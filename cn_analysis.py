"""
ì¤‘êµ­ìš© ë¶„ì„ ë„êµ¬ - ëª¨ë“  ê¸°ëŠ¥ì´ í•˜ë‚˜ì˜ íŒŒì¼ì— í†µí•©ë¨
- SQL ì¿¼ë¦¬ ì‹¤í–‰
- LLM í˜¸ì¶œ (Claude)
- Markdown/JSON íŒŒì¼ ì €ì¥
"""

import os
import json
import polars as pl
import anthropic
from datetime import datetime, timedelta
from decimal import Decimal
from sqlalchemy import create_engine
from snowflake.sqlalchemy import URL
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ============================================================================
# ì„¤ì •
# ============================================================================
BRAND_CODE_MAP = {
    # ì¤‘êµ­ìš© ë¸Œëœë“œ ì½”ë“œ ë§¤í•‘ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
    'M': 'MLB',
    'I': 'MLB KIDS',
    'X': 'DISCOVERY',
    'V': 'DUVETICA',
    'ST': 'SERGIO TACCHINI',
    'W': 'SUPRA',
}

OUTPUT_JSON_PATH = './cn_output/json'
OUTPUT_MD_PATH = './cn_output/md'

# ì¶œë ¥ í´ë” ìƒì„±
os.makedirs(OUTPUT_JSON_PATH, exist_ok=True)
os.makedirs(OUTPUT_MD_PATH, exist_ok=True)

# ì±„ë„ ìˆœì„œ ì •ì˜ (JSON/MD ì¶”ì¶œ ì‹œ ì‚¬ìš©)
CHANNEL_ORDER = [
    '(EC)í‹°ëª°',
    '(EC)í‹±í†¡/JD',
    '(EC)í• ì¸ëª°',
    '(OFF)í”Œë˜ê·¸ì‰½',
    '(OFF)ì‡¼í•‘ëª°',
    '(OFF)ì•„ìš¸ë ›',
    '(EC)ëŒ€ë¦¬ìƒ',
    '(OFF)ëŒ€ë¦¬ìƒ',
]

# ============================================================================
# DB ì—°ê²°
# ============================================================================
def get_db_engine():
    """Snowflake DB ì—°ê²° ì—”ì§„ ìƒì„±"""
    account = os.getenv('SNOWFLAKE_ACCOUNT')
    user = os.getenv('SNOWFLAKE_USER')
    password = os.getenv('SNOWFLAKE_PASSWORD')
    database = os.getenv('SNOWFLAKE_DATABASE')
    schema = os.getenv('SNOWFLAKE_SCHEMA')
    warehouse = os.getenv('SNOWFLAKE_WAREHOUSE')
    role = os.getenv('SNOWFLAKE_ROLE')
    
    if not all([account, user, password, database, schema, warehouse, role]):
        raise ValueError("Snowflake í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    return create_engine(
        URL(
            account=account,
            user=user,
            password=password,
            database=database,
            schema=schema,
            warehouse=warehouse,
            role=role,
        )
    )

# ============================================================================
# SQL ì¿¼ë¦¬ ì‹¤í–‰
# ============================================================================
def run_query(sql, engine):
    """SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ê³  DataFrame ë°˜í™˜"""
    print(f"[SQL] ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
    df = pl.read_database(sql, engine)
    print(f"[OK] {len(df)}ê°œ í–‰ ì¡°íšŒ ì™„ë£Œ")
    return df

# ============================================================================
# LLM í˜¸ì¶œ
# ============================================================================
# ì „ì—­ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
_total_tokens_used = {'input': 0, 'output': 0}

def call_llm(prompt, max_tokens=4000, temperature=0.7):
    """Claude API í˜¸ì¶œ"""
    api_key = os.getenv('CLAUDE_API_KEY')
    if not api_key:
        raise ValueError("CLAUDE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    client = anthropic.Anthropic(api_key=api_key, timeout=120.0)
    
    system_prompt = """
ë‹¹ì‹ ì€ F&F ê·¸ë£¹ì˜ ìµœê³  ì „ëµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:

ğŸ“Š **ë¶„ì„ ì›ì¹™**
- ìˆ«ìëŠ” ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ê³  ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ëª¨ë“  ê¸ˆì•¡ì€ k(ì²œ) ë‹¨ìœ„ë¡œ í‘œì‹œ (ì›ë³¸ ë°ì´í„°ë¥¼ 1,000ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œê¸°)
- ë‹¨ìœ„ëŠ” k, 3ìë¦¬ë§ˆë‹¤ ì‰¼í‘œ í‘œê¸°
- âš ï¸ **ì¤‘ìš”: ì²œ ë‹¨ìœ„ í‘œì‹œ ì‹œ ë°˜ë“œì‹œ ì •ìˆ˜ë¡œ í‘œê¸°í•˜ê³  ì†Œìˆ˜ì ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ**
  - ì˜¬ë°”ë¥¸ ì˜ˆ: 1,234k, 588k, 1,378k
  - ì˜ëª»ëœ ì˜ˆ: 1,234.56k, 588.67k, 1,378.0k (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)
  - ì†Œìˆ˜ì ì´ ìˆëŠ” ê²½ìš° ë°˜ì˜¬ë¦¼í•˜ì—¬ ì •ìˆ˜ë¡œ í‘œê¸° (ì˜ˆ: 588.67 â†’ 589k, 1,378.0 â†’ 1,378k)
- ë¹„ì¤‘(%)ì€ ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ í‘œí˜„
- ë§¤ì¶œì•¡ì€ act_sale_amt ì»¬ëŸ¼ ì‚¬ìš©í• ê²ƒ ë§¤ì¶œì•¡(v+)ë¼ê³  í‘œí˜„í•˜ê¸°
- í• ì¸ìœ¨ ê³„ì‚°ì€ act_sale_amt / tag_sale_amt ì‚¬ìš©
- ì§ì ‘ì´ìµë¥  ê³„ì‚° ì‹œ ì§ì—…ì´ìµ / (act_sale_amt/1.1) ì‚¬ìš©
- ì˜ì—…ì´ìµë¥  ê³„ì‚° ì‹œ ì˜ì—…ì´ìµ / (act_sale_amt/1.1) ì‚¬ìš©

ğŸ¯ **ë³´ê³  ìŠ¤íƒ€ì¼**
- ê²½ì˜ê´€ë¦¬íŒ€ ëŒ€ìƒì˜ ì „ëµì  ê´€ì 
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì•¡ì…˜í”Œëœ ì œì‹œ
- ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒë¥¼ ëª…í™•íˆ êµ¬ë¶„
- ê·¼ê±° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„
- ì´ìƒì§•í›„ë‚˜ íŠ¹ì´ì‚¬í•­ ì–¸ê¸‰
"""
    
    full_prompt = system_prompt + "\n\n" + prompt
    
    print(f"[LLM] Claude API í˜¸ì¶œ ì¤‘...")
    message = client.messages.create(
        model='claude-sonnet-4-20250514',
        max_tokens=max_tokens,
        temperature=temperature,
        messages=[{"role": "user", "content": full_prompt}]
    )
    
    # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
    if hasattr(message, 'usage') and message.usage:
        input_tokens = message.usage.input_tokens if hasattr(message.usage, 'input_tokens') else 0
        output_tokens = message.usage.output_tokens if hasattr(message.usage, 'output_tokens') else 0
        _total_tokens_used['input'] += input_tokens
        _total_tokens_used['output'] += output_tokens
        print(f"[OK] LLM ì‘ë‹µ ì™„ë£Œ (ì…ë ¥: {input_tokens:,} í† í°, ì¶œë ¥: {output_tokens:,} í† í°, ì´: {input_tokens + output_tokens:,} í† í°)")
    else:
        print(f"[OK] LLM ì‘ë‹µ ì™„ë£Œ")
    
    return message.content[0].text

def get_total_tokens():
    """ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
    return _total_tokens_used.copy()

def reset_token_counter():
    """í† í° ì¹´ìš´í„° ì´ˆê¸°í™”"""
    global _total_tokens_used
    _total_tokens_used = {'input': 0, 'output': 0}

# ============================================================================
# íŒŒì¼ ì €ì¥
# ============================================================================
def save_markdown(content, filename):
    """Markdown íŒŒì¼ ì €ì¥"""
    # KEY, sub_key, country ì¶”ì¶œ
    key, sub_key, country = extract_key_from_filename(filename)
    
    # YAML frontmatter ì¶”ê°€
    frontmatter_lines = ["---"]
    if key:
        frontmatter_lines.append(f"key: {key}")
    if sub_key:
        frontmatter_lines.append(f"sub_key: {sub_key}")
    frontmatter_lines.append(f"country: {country}")
    frontmatter_lines.append("---")
    frontmatter = "\n".join(frontmatter_lines) + "\n\n"
    
    # content ì•ì— frontmatter ì¶”ê°€
    full_content = frontmatter + content
    
    file_path = os.path.join(OUTPUT_MD_PATH, f"{filename}.md")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(full_content)
    print(f"[OK] Markdown ì €ì¥: {file_path}")
    return file_path

class DecimalEncoder(json.JSONEncoder):
    """Decimal íƒ€ì…ì„ floatë¡œ ë³€í™˜í•˜ëŠ” JSON ì¸ì½”ë”"""
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)
        return super(DecimalEncoder, self).default(obj)

def json_dumps_safe(obj, **kwargs):
    """Decimal íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” json.dumps ë˜í¼"""
    return json.dumps(obj, cls=DecimalEncoder, **kwargs)

def extract_json_from_response(text):
    """
    AI ì‘ë‹µì—ì„œ JSON ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±
    
    Args:
        text: AI ì‘ë‹µ í…ìŠ¤íŠ¸ (JSON ì½”ë“œ ë¸”ë¡ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ)
    
    Returns:
        dict: íŒŒì‹±ëœ JSON ë°ì´í„°, ì‹¤íŒ¨ ì‹œ None
    """
    import re
    
    if not text:
        return None
    
    # 1. JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸° (```json ... ```)
    json_block_pattern = r'```json\s*(.*?)\s*```'
    match = re.search(json_block_pattern, text, re.DOTALL)
    
    if match:
        json_str = match.group(1).strip()
    else:
        # 2. ì½”ë“œ ë¸”ë¡ ì—†ìœ¼ë©´ ``` ... ``` ì°¾ê¸°
        code_block_pattern = r'```\s*(.*?)\s*```'
        match = re.search(code_block_pattern, text, re.DOTALL)
        if match:
            json_str = match.group(1).strip()
            # json ë§ˆì»¤ ì œê±°
            if json_str.startswith('json'):
                json_str = json_str[4:].strip()
        else:
            # 3. ì½”ë“œ ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì°¾ê¸°
            # { ë¡œ ì‹œì‘í•˜ê³  } ë¡œ ëë‚˜ëŠ” ë¶€ë¶„ ì°¾ê¸° (ì¤‘ì²©ëœ ì¤‘ê´„í˜¸ ì²˜ë¦¬)
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            match = re.search(json_pattern, text, re.DOTALL)
            if match:
                json_str = match.group(0)
            else:
                json_str = text.strip()
    
    # JSON íŒŒì‹± ì‹œë„
    try:
        parsed = json.loads(json_str)
        print(f"[OK] JSON íŒŒì‹± ì„±ê³µ: {len(parsed.get('sections', []))}ê°œ ì„¹ì…˜ ì¶”ì¶œ")
        return parsed
    except json.JSONDecodeError as e:
        print(f"[WARNING] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)[:100]}")
        # ë§ˆì§€ë§‰ ì‹œë„: ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€ ì¶”ì¶œ
        try:
            start_idx = text.find('{')
            end_idx = text.rfind('}')
            if start_idx >= 0 and end_idx > start_idx:
                json_str = text[start_idx:end_idx+1]
                parsed = json.loads(json_str)
                print(f"[OK] JSON íŒŒì‹± ì„±ê³µ (ì¬ì‹œë„): {len(parsed.get('sections', []))}ê°œ ì„¹ì…˜ ì¶”ì¶œ")
                return parsed
        except:
            pass
        return None

def sort_channels_by_order(channel_dict):
    """
    ì±„ë„ ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ì˜ëœ ìˆœì„œë¡œ ì •ë ¬
    
    Args:
        channel_dict: ì±„ë„ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    
    Returns:
        OrderedDict: ì •ë ¬ëœ ì±„ë„ ë”•ì…”ë„ˆë¦¬
    """
    from collections import OrderedDict
    
    ordered_dict = OrderedDict()
    
    # ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ ì±„ë„ ì¶”ê°€
    for channel in CHANNEL_ORDER:
        if channel in channel_dict:
            ordered_dict[channel] = channel_dict[channel]
    
    # ì •ì˜ëœ ìˆœì„œì— ì—†ëŠ” ì±„ë„ë“¤ì€ ë’¤ì— ì¶”ê°€ (ì•ŒíŒŒë²³ ìˆœì„œ)
    remaining_channels = sorted([
        (k, v) for k, v in channel_dict.items() 
        if k not in CHANNEL_ORDER
    ])
    for channel, data in remaining_channels:
        ordered_dict[channel] = data
    
    return ordered_dict

def get_channel_list_sorted(channel_dict):
    """
    ì±„ë„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ì˜ëœ ìˆœì„œë¡œ ì •ë ¬
    
    Args:
        channel_dict: ì±„ë„ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    
    Returns:
        list: ì •ë ¬ëœ ì±„ë„ëª… ë¦¬ìŠ¤íŠ¸
    """
    sorted_list = []
    
    # ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ ì±„ë„ ì¶”ê°€
    for channel in CHANNEL_ORDER:
        if channel in channel_dict:
            sorted_list.append(channel)
    
    # ì •ì˜ëœ ìˆœì„œì— ì—†ëŠ” ì±„ë„ë“¤ì€ ë’¤ì— ì¶”ê°€ (ì•ŒíŒŒë²³ ìˆœì„œ)
    remaining_channels = sorted([
        k for k in channel_dict.keys() 
        if k not in CHANNEL_ORDER
    ])
    sorted_list.extend(remaining_channels)
    
    return sorted_list

def extract_key_from_filename(filename):
    """
    íŒŒì¼ëª…ì—ì„œ KEYì™€ sub_keyë¥¼ ì¶”ì¶œ (ë¸Œëœë“œ ì½”ë“œ ì œì™¸)
    
    íŒŒì¼ëª… í˜•ì‹: CN_{yyyymm_short}_{brd_cd}_{ë¶„ì„íƒ€ì…}_{ì„¸ë¶€ë¶„ì„}
    ì˜ˆì‹œ: CN_2509_M_ë¦¬í…Œì¼ë§¤ì¶œ_ì±„ë„ë³„ë§¤ì¶œë¶„ì„
    
    Returns:
        tuple: (key, sub_key, country)
        - key: ë¶„ì„íƒ€ì…ë§Œ (ì˜ˆ: ë¦¬í…Œì¼)
        - sub_key: ì„¸ë¶€ë¶„ì„ë§Œ (ì˜ˆ: ì±„ë„ë³„ë§¤ì¶œë¶„ì„)
        - country: CN
    """
    # CN_2509_M_ë¦¬í…Œì¼ë§¤ì¶œ_ì±„ë„ë³„ë§¤ì¶œë¶„ì„ í˜•ì‹
    parts = filename.split('_')
    if len(parts) < 4:
        return None, None, 'CN'
    
    # CN ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì‚¬ìš©
    if parts[0] == 'CN':
        parts = parts[1:]  # ['2509', 'M', 'ë¦¬í…Œì¼', 'ì±„ë„ë³„ë§¤ì¶œë¶„ì„']
    
    if len(parts) < 3:
        return None, None, 'CN'
    
    # yyyymm_short, brd_cd, ë‚˜ë¨¸ì§€
    analysis_parts = parts[2:]  # ['ë¦¬í…Œì¼', 'ì±„ë„ë³„ë§¤ì¶œë¶„ì„']
    
    if len(analysis_parts) == 0:
        return None, None, 'CN'
    
    # KEY: ì²«ë²ˆì§¸ ë¶„ì„íƒ€ì…ë§Œ (ë¸Œëœë“œ ì½”ë“œ ì œì™¸)
    key = analysis_parts[0]  # 'ë¦¬í…Œì¼'
    
    # sub_key: ë‘ë²ˆì§¸ë¶€í„° ëê¹Œì§€ (ë¸Œëœë“œ ì½”ë“œ ì œì™¸)
    if len(analysis_parts) > 1:
        sub_key = '_'.join(analysis_parts[1:])  # 'ì±„ë„ë³„ë§¤ì¶œë¶„ì„'
    else:
        sub_key = None
    
    return key, sub_key, 'CN'

def save_json(data, filename):
    """JSON íŒŒì¼ ì €ì¥ - í•„ë“œ ìˆœì„œ: country, brand_cd, brand_name, yyyymm, yyyymm_py, key, sub_key, analysis_data, ..."""
    # KEY, sub_key, country ì¶”ì¶œ
    key, sub_key, country = extract_key_from_filename(filename)
    
    # JSON ë°ì´í„°ì— KEY, sub_key, country ì¶”ê°€ (ì§€ì •ëœ ìˆœì„œë¡œ)
    if isinstance(data, dict):
        # ìˆœì„œë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ OrderedDict ì‚¬ìš©
        from collections import OrderedDict
        new_data = OrderedDict()
        
        # 1. country (í•­ìƒ ì²« ë²ˆì§¸)
        if 'country' in data:
            new_data['country'] = data['country']
        elif country:
            new_data['country'] = country
        
        # 2. brand_cd
        if 'brand_cd' in data:
            new_data['brand_cd'] = data['brand_cd']
        
        # 3. brand_name
        if 'brand_name' in data:
            new_data['brand_name'] = data['brand_name']
        
        # 4. yyyymm
        if 'yyyymm' in data:
            new_data['yyyymm'] = data['yyyymm']
        
        # 5. yyyymm_py
        if 'yyyymm_py' in data:
            new_data['yyyymm_py'] = data['yyyymm_py']
        
        # 6. key
        if 'key' in data:
            new_data['key'] = data['key']
        elif key:
            new_data['key'] = key
        
        # 7. sub_key
        if 'sub_key' in data:
            new_data['sub_key'] = data['sub_key']
        elif sub_key:
            new_data['sub_key'] = sub_key
        
        # 8. analysis_data
        if 'analysis_data' in data:
            new_data['analysis_data'] = data['analysis_data']
        
        # ë‚˜ë¨¸ì§€ í•„ë“œë“¤ (summary, channel_summary, raw_data ë“±)
        for k, v in data.items():
            if k not in ['country', 'brand_cd', 'brand_name', 'yyyymm', 'yyyymm_py', 'key', 'sub_key', 'analysis_data']:
                new_data[k] = v
        
        data = dict(new_data)  # OrderedDictë¥¼ ì¼ë°˜ dictë¡œ ë³€í™˜ (Python 3.7+ì—ì„œëŠ” ìˆœì„œ ë³´ì¥)
    
    file_path = os.path.join(OUTPUT_JSON_PATH, f"{filename}.json")
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, cls=DecimalEncoder)
    print(f"[OK] JSON ì €ì¥: {file_path}")
    return file_path

# ============================================================================
# SQL ì¿¼ë¦¬ í•¨ìˆ˜ë“¤ (ì‚¬ìš©ìê°€ ì±„ì›Œë„£ì„ ë¶€ë¶„)
# ============================================================================
def get_retail_channel_sales_query(yyyymm, yyyymm_py, brd_cd):
    """
    ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
    
    Args:
        yyyymm: ë‹¹í•´ ë…„ì›” (ì˜ˆ: '202510')
        yyyymm_py: ì „ë…„ ë™ì›” (ì˜ˆ: '202410')
        brd_cd: ë¸Œëœë“œ ì½”ë“œ
    
    Returns:
        str: SQL ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # TODO: SQL ì¿¼ë¦¬ ì‘ì„± í•„ìš”
    sql = f"""
    -- ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„ ì¿¼ë¦¬
    -- ë‹¹í•´: {yyyymm}, ì „ë…„: {yyyymm_py}, ë¸Œëœë“œ: {brd_cd}
    with param as (
  select 'CY' as div
     , '{yyyymm}' as std_yyyymm
  union all
  select 'PY' as div
     , '{yyyymm_py}' as std_yyyymm
)
, chnl_std as (
    select map_shop_agnt_cd  -- ë§¤ì¥, ëŒ€ë¼ìƒ ì½”ë“œ
         , mgmt_chnl_nm as chnl_std  -- ì±„ë„ëª…
    from sap_fnf.mst_shop
    group by 1,2
)
, raw as (
    select a.yymm
        , a.brd_cd
        , b.chnl_std
        , c.prdt_hrrc3_nm as class3 -- ì•„ì´í…œ
        , a.prdt_cd -- í’ˆë²ˆ
        , max(c.prdt_nm) as prdt_nm -- ì œí’ˆëª…
        , sum(a.sale_amt) sale_amt -- ì‹¤íŒê°€ v+
    from chn.dm_sh_s_m a -- bos ë§¤ì¶œ
    join chnl_std b
      on a.map_shop_agnt_cd = b.map_shop_agnt_cd
    join sap_fnf.mst_prdt c
      on a.prdt_cd = c.prdt_cd
    join param p
      on a.yymm = p.std_yyyymm
    where 1=1
      and a.brd_cd = '{brd_cd}'
    group by a.yymm
        , a.brd_cd
        , b.chnl_std
        , c.prdt_hrrc3_nm
        , a.prdt_cd
)
select *
from raw
    """
    return sql

def get_outbound_category_sales_query(yyyymm, yyyymm_py, brd_cd):
    """
    ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
    
    Args:
        yyyymm: ë‹¹í•´ ë…„ì›” (ì˜ˆ: '202510')
        yyyymm_py: ì „ë…„ ë™ì›” (ì˜ˆ: '202410')
        brd_cd: ë¸Œëœë“œ ì½”ë“œ
    
    Returns:
        str: SQL ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # TODO: SQL ì¿¼ë¦¬ ì‘ì„± í•„ìš”
    sql = f"""
    -- ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„ ì¿¼ë¦¬
    -- ë‹¹í•´: {yyyymm}, ì „ë…„: {yyyymm_py}, ë¸Œëœë“œ: {brd_cd}
    SELECT 
        -- ì—¬ê¸°ì— SQL ì¿¼ë¦¬ ì‘ì„±
        1 as placeholder
    """
    return sql

def get_agent_store_sales_query(yyyymm, yyyymm_py, brd_cd):
    """
    ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
    
    Args:
        yyyymm: ë‹¹í•´ ë…„ì›” (ì˜ˆ: '202510')
        yyyymm_py: ì „ë…„ ë™ì›” (ì˜ˆ: '202410')
        brd_cd: ë¸Œëœë“œ ì½”ë“œ
    
    Returns:
        str: SQL ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # TODO: SQL ì¿¼ë¦¬ ì‘ì„± í•„ìš”
    sql = f"""
    -- ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬
    -- ë‹¹í•´: {yyyymm}, ì „ë…„: {yyyymm_py}, ë¸Œëœë“œ: {brd_cd}
    SELECT 
        -- ì—¬ê¸°ì— SQL ì¿¼ë¦¬ ì‘ì„±
        1 as placeholder
    """
    return sql

def get_discount_rate_query(yyyymm, yyyymm_py, brd_cd):
    """
    í• ì¸ìœ¨ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
    
    Args:
        yyyymm: ë‹¹í•´ ë…„ì›” (ì˜ˆ: '202510')
        yyyymm_py: ì „ë…„ ë™ì›” (ì˜ˆ: '202410')
        brd_cd: ë¸Œëœë“œ ì½”ë“œ
    
    Returns:
        str: SQL ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # TODO: SQL ì¿¼ë¦¬ ì‘ì„± í•„ìš”
    sql = f"""
    -- í• ì¸ìœ¨ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬
    -- ë‹¹í•´: {yyyymm}, ì „ë…„: {yyyymm_py}, ë¸Œëœë“œ: {brd_cd}
    SELECT 
        -- ì—¬ê¸°ì— SQL ì¿¼ë¦¬ ì‘ì„±
        1 as placeholder
    """
    return sql

def get_operating_expense_query(yyyymm, yyyymm_py, brd_cd):
    """
    ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
    
    Args:
        yyyymm: ë‹¹í•´ ë…„ì›” (ì˜ˆ: '202510')
        yyyymm_py: ì „ë…„ ë™ì›” (ì˜ˆ: '202410')
        brd_cd: ë¸Œëœë“œ ì½”ë“œ
    
    Returns:
        str: SQL ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # TODO: SQL ì¿¼ë¦¬ ì‘ì„± í•„ìš”
    sql = f"""
    -- ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„ ì¿¼ë¦¬
    -- ë‹¹í•´: {yyyymm}, ì „ë…„: {yyyymm_py}, ë¸Œëœë“œ: {brd_cd}
    SELECT 
        -- ì—¬ê¸°ì— SQL ì¿¼ë¦¬ ì‘ì„±
        1 as placeholder
    """
    return sql

# ============================================================================
# ë¶„ì„ í•¨ìˆ˜ë“¤
# ============================================================================
def analyze_retail_channel_sales(yyyymm, brd_cd):
    """ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_retail_channel_sales_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records if 'SALE_AMT' in r)
        unique_channels = len(set(r.get('CHNL_STD', '') for r in records if r.get('CHNL_STD')))
        unique_items = len(set(r.get('CLASS3', '') for r in records if r.get('CLASS3')))
        
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        print(f"ì±„ë„ ìˆ˜: {unique_channels}ê°œ")
        print(f"ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ")
        
        # ì±„ë„ë³„ ìš”ì•½ ë°ì´í„° ìƒì„±
        channel_summary = {}
        for record in records:
            chnl_std = record.get('CHNL_STD', 'ê¸°íƒ€')
            yymm = record.get('YYMM', '')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            if chnl_std not in channel_summary:
                channel_summary[chnl_std] = {
                    'total_sales': 0,
                    'months': {},
                    'top_items': []
                }
            
            channel_summary[chnl_std]['total_sales'] += sale_amt
            
            if yymm not in channel_summary[chnl_std]['months']:
                channel_summary[chnl_std]['months'][yymm] = 0
            channel_summary[chnl_std]['months'][yymm] += sale_amt
        
        # ì±„ë„ë³„ ìƒìœ„ ì•„ì´í…œ ì¶”ì¶œ
        item_sales_by_channel = {}
        for record in records:
            chnl_std = record.get('CHNL_STD', 'ê¸°íƒ€')
            class3 = record.get('CLASS3', 'ê¸°íƒ€')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            key = f"{chnl_std}|{class3}"
            if key not in item_sales_by_channel:
                item_sales_by_channel[key] = {
                    'chnl_std': chnl_std,
                    'class3': class3,
                    'total_sales': 0
                }
            item_sales_by_channel[key]['total_sales'] += sale_amt
        
        # ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œ ì•„ì´í…œ ì¶”ì¶œ
        for chnl_std in channel_summary:
            items = [
                {'class3': v['class3'], 'total_sales': v['total_sales']}
                for k, v in item_sales_by_channel.items()
                if v['chnl_std'] == chnl_std
            ]
            items.sort(key=lambda x: x['total_sales'], reverse=True)
            channel_summary[chnl_std]['top_items'] = items[:5]
        
        # ë‹¹í•´/ì „ë…„ ë¹„êµ ë°ì´í„° ìƒì„±
        total_sales_cy = sum(
            float(r.get('SALE_AMT', 0)) for r in records 
            if r.get('YYMM') == yyyymm and 'SALE_AMT' in r
        )
        total_sales_py = sum(
            float(r.get('SALE_AMT', 0)) for r in records 
            if r.get('YYMM') == yyyymm_py and 'SALE_AMT' in r
        )
        change_pct = ((total_sales_cy - total_sales_py) / total_sales_py * 100) if total_sales_py > 0 else 0
        
        # ì±„ë„ë³„ ë‹¹í•´/ì „ë…„ ë¹„êµ
        channel_comparison = {}
        for chnl_std in channel_summary:
            sales_cy = channel_summary[chnl_std]['months'].get(yyyymm, 0)
            sales_py = channel_summary[chnl_std]['months'].get(yyyymm_py, 0)
            change = ((sales_cy - sales_py) / sales_py * 100) if sales_py > 0 else 0
            channel_comparison[chnl_std] = {
                'sales_cy': sales_cy,
                'sales_py': sales_py,
                'change_pct': round(change, 1)
            }
        
        # ì±„ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        channel_summary_sorted = sort_channels_by_order(channel_summary)
        channel_comparison_sorted = sort_channels_by_order(channel_comparison)
        sorted_channel_list = get_channel_list_sorted(channel_summary)
        
        # AI ë¶„ì„ ìš”ì²­
        prompt = f"""
ë‹¤ìŒì€ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

**ë¶„ì„ ê¸°ê°„**: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”

**ì „ì²´ ìš”ì•½**:
- ì´ ë§¤ì¶œì•¡ (ë‹¹í•´): {total_sales_cy/1000000:.2f}ë°±ë§Œì›
- ì´ ë§¤ì¶œì•¡ (ì „ë…„): {total_sales_py/1000000:.2f}ë°±ë§Œì›
- ì „ë…„ ëŒ€ë¹„ ë³€í™”: {change_pct:.1f}%
- ì±„ë„ ìˆ˜: {unique_channels}ê°œ
- ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ

**ì±„ë„ ë¶„ì„ ìˆœì„œ** (ë°˜ë“œì‹œ ì´ ìˆœì„œëŒ€ë¡œ ë¶„ì„í•˜ì„¸ìš”):
{', '.join(sorted_channel_list)}

**ì±„ë„ë³„ ìš”ì•½ ë°ì´í„°** (ì •ë ¬ëœ ìˆœì„œ):
{json_dumps_safe(dict(channel_summary_sorted), ensure_ascii=False, indent=2)}

**ì±„ë„ë³„ ë‹¹í•´/ì „ë…„ ë¹„êµ** (ì •ë ¬ëœ ìˆœì„œ):
{json_dumps_safe(dict(channel_comparison_sorted), ensure_ascii=False, indent=2)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê° ì±„ë„ë³„ ë¶„ì„** (ì±„ë„ë³„ë¡œ DIVë¥¼ ìƒì„±):
   - ê° ì±„ë„ì˜ ë§¤ì¶œ í˜„í™© ë° ì „ë…„ ëŒ€ë¹„ ë³€í™”ìœ¨
   - ê° ì±„ë„ì˜ TOP 3 ì•„ì´í…œ ë¶„ì„
   - ê° ì±„ë„ì˜ ì„±ê³¼ ìš”ì•½ ë° ì „ëµì  ì‹œì‚¬ì 

2. **ì¢…í•©ë¶„ì„** (ì¢…í•©ë¶„ì„-1, ì¢…í•©ë¶„ì„-2, ì¢…í•©ë¶„ì„-3ìœ¼ë¡œ DIV ìƒì„±):
   - ì¢…í•©ë¶„ì„-1: ìµœê³  ì„±ê³¼ ì±„ë„ ë¶„ì„ (ë§¤ì¶œì•¡, ì„±ì¥ë¥ , ì£¼ìš” ì„±ê³µ ìš”ì¸)
   - ì¢…í•©ë¶„ì„-2: ê°œì„  í•„ìš” ì±„ë„ ë¶„ì„ (í•˜ë½ ì±„ë„, ì›ì¸ ë¶„ì„, ê°œì„  ë°©ì•ˆ)
   - ì¢…í•©ë¶„ì„-3: í•µì‹¬ ì œì•ˆ (ì „ì²´ ì±„ë„ ì „ëµ, ìš°ì„ ìˆœìœ„ ì•¡ì…˜í”Œëœ)

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "title": "ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„",
    "sections": [
        {{
            "div": "ì±„ë„ëª…1",
            "sub_title": "ì±„ë„ëª…1 ì „ë…„ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ì±„ë„ë³„ ìƒì„¸ ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "div": "ì±„ë„ëª…2",
            "sub_title": "ì±„ë„ëª…2 ì „ë…„ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ì±„ë„ë³„ ìƒì„¸ ë¶„ì„ ë‚´ìš©..."
        }},
        ... (ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ë°˜ë³µ) ...
        {{
            "div": "ì¢…í•©ë¶„ì„-1",
            "sub_title": "ìµœê³  ì„±ê³¼ ì±„ë„",
            "ai_text": "ìµœê³  ì„±ê³¼ ì±„ë„ ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "div": "ì¢…í•©ë¶„ì„-2",
            "sub_title": "ê°œì„  í•„ìš” ì±„ë„",
            "ai_text": "ê°œì„  í•„ìš” ì±„ë„ ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "div": "ì¢…í•©ë¶„ì„-3",
            "sub_title": "í•µì‹¬ ì œì•ˆ",
            "ai_text": "í•µì‹¬ ì œì•ˆ ë‚´ìš©..."
        }}
    ]
}}

**ì¤‘ìš”**: 
- ê° ì±„ë„ë³„ë¡œ "div" í•„ë“œì— ì±„ë„ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”
- ì±„ë„ë³„ ë¶„ì„ì€ ë°˜ë“œì‹œ ìœ„ì— ëª…ì‹œëœ "ì±„ë„ ë¶„ì„ ìˆœì„œ"ëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ì¢…í•©ë¶„ì„ì€ ë°˜ë“œì‹œ "ì¢…í•©ë¶„ì„-1", "ì¢…í•©ë¶„ì„-2", "ì¢…í•©ë¶„ì„-3"ìœ¼ë¡œ div í•„ë“œë¥¼ ì„¤ì •í•˜ì„¸ìš”
- ì±„ë„ë³„ ë¶„ì„ì„ ë¨¼ì € ì‘ì„±í•˜ê³ , ê·¸ ë‹¤ìŒ ì¢…í•©ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”
"""
        
        ai_response = call_llm(prompt)
        
        # AI ì‘ë‹µ íŒŒì‹± (JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ)
        analysis_data = extract_json_from_response(ai_response)
        
        # íŒŒì‹± ê²°ê³¼ ê²€ì¦ ë° ì •ë¦¬
        if analysis_data is None or not isinstance(analysis_data, dict):
            print(f"[WARNING] JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë¡œ ì €ì¥")
            analysis_data = {
                'title': 'ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„',
                'sections': [
                    {
                        'sub_title': 'ë¶„ì„ ê²°ê³¼',
                        'ai_text': ai_response
                    }
                ]
            }
        else:
            # sections ë°°ì—´ ê²€ì¦
            if 'sections' not in analysis_data or not isinstance(analysis_data['sections'], list):
                print(f"[WARNING] sections ë°°ì—´ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ, ì¬êµ¬ì„±")
                analysis_data = {
                    'title': analysis_data.get('title', 'ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„'),
                    'sections': [
                        {
                            'sub_title': 'ë¶„ì„ ê²°ê³¼',
                            'ai_text': ai_response
                        }
                    ]
                }
            else:
                # sectionsì˜ ê° í•­ëª©ì´ ì˜¬ë°”ë¥¸ êµ¬ì¡°ì¸ì§€ í™•ì¸
                valid_sections = []
                for section in analysis_data['sections']:
                    if isinstance(section, dict) and 'ai_text' in section:
                        valid_sections.append(section)
                    else:
                        print(f"[WARNING] ì˜ëª»ëœ section êµ¬ì¡° ë°œê²¬, ê±´ë„ˆëœ€: {section}")
                
                if valid_sections:
                    analysis_data['sections'] = valid_sections
                    print(f"[OK] {len(valid_sections)}ê°œ ì„¹ì…˜ì´ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±ë¨")
                else:
                    print(f"[WARNING] ìœ íš¨í•œ ì„¹ì…˜ì´ ì—†ìŒ, í…ìŠ¤íŠ¸ë¡œ ì €ì¥")
                    analysis_data = {
                        'title': analysis_data.get('title', 'ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„'),
                        'sections': [
                            {
                                'sub_title': 'ë¶„ì„ ê²°ê³¼',
                                'ai_text': ai_response
                            }
                        ]
                    }
        
        # JSON ë°ì´í„° êµ¬ì„±
        # channel_summaryë¥¼ ë°±ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ê³  ì •ë ¬ëœ ìˆœì„œë¡œ ì €ì¥
        from collections import OrderedDict
        channel_summary_formatted = OrderedDict()
        for chnl_std, data in channel_summary_sorted.items():
            channel_summary_formatted[chnl_std] = {
                'total_sales': round(data['total_sales'] / 1000000, 2),
                'months': {
                    k: round(v / 1000000, 2) for k, v in data['months'].items()
                },
                'top_items': [
                    {
                        'class3': item['class3'],
                        'total_sales': round(item['total_sales'] / 1000000, 2)
                    }
                    for item in data['top_items']
                ]
            }
        
        json_data = {
            'country': 'CN',
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'key': 'ë¦¬í…Œì¼',
            'sub_key': 'ì±„ë„ë³„ë§¤ì¶œë¶„ì„',
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'total_sales_cy': round(total_sales_cy / 1000000, 2),
                'total_sales_py': round(total_sales_py / 1000000, 2),
                'change_pct': round(change_pct, 1),
                'unique_channels': unique_channels,
                'unique_items': unique_items,
                'unique_months': 2,
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'channel_summary': channel_summary_formatted,
            'raw_data': {
                'sample_records': [dict(r) for r in records[:50]],
                'total_records_count': len(records)
            }
        }
        
        # íŒŒì¼ ì €ì¥
        yyyymm_short = yyyymm[2:]  # 202510 -> 2510
        filename = f"CN_{yyyymm_short}_{brd_cd}_ë¦¬í…Œì¼ë§¤ì¶œ_ì±„ë„ë³„ë§¤ì¶œë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥ (ì±„ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬)
        markdown_content = f"# {analysis_data.get('title', 'ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„')}\n\n"
        
        # sectionsë¥¼ ì±„ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        sections = analysis_data.get('sections', [])
        
        # ì±„ë„ë³„ sectionsì™€ ì¢…í•©ë¶„ì„ sections ë¶„ë¦¬
        channel_sections = []
        overall_sections = []
        other_sections = []
        
        for section in sections:
            div = section.get('div', '')
            if div.startswith('ì¢…í•©ë¶„ì„'):
                overall_sections.append(section)
            elif div in sorted_channel_list:
                channel_sections.append((sorted_channel_list.index(div), section))
            else:
                other_sections.append(section)
        
        # ì±„ë„ë³„ sectionsë¥¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        channel_sections.sort(key=lambda x: x[0])
        
        # Markdown ìƒì„±: ì±„ë„ë³„ â†’ ì¢…í•©ë¶„ì„ â†’ ê¸°íƒ€
        for _, section in channel_sections:
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        
        for section in overall_sections:
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        
        for section in other_sections:
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_outbound_category_sales(yyyymm, brd_cd):
    """ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_outbound_category_sales_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records if 'SALE_AMT' in r)
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        
        # TODO: ë°ì´í„° ê°€ê³µ ë° ë¶„ì„ ë¡œì§ ì‘ì„±
        
        # AI ë¶„ì„ ìš”ì²­
        prompt = f"""
ë‹¤ìŒì€ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

**ë¶„ì„ ê¸°ê°„**: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”

**ë°ì´í„° ìš”ì•½**:
- ì´ ë§¤ì¶œì•¡: {total_sales/1000000:.2f}ë°±ë§Œì›
- ì´ ë ˆì½”ë“œ ìˆ˜: {len(records)}ê°œ

**ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ** (ìµœëŒ€ 50ê°œ):
{json_dumps_safe([dict(r) for r in records[:50]], ensure_ascii=False, indent=2)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ í˜„í™© ë° ì „ë…„ ëŒ€ë¹„ ë³€í™”
2. ì£¼ìš” ì¹´í…Œê³ ë¦¬ì˜ ì„±ê³¼ ë¶„ì„
3. ì „ëµì  ì‹œì‚¬ì  ë° ì•¡ì…˜í”Œëœ

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "title": "ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„",
    "sections": [
        {{
            "sub_title": "ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ í˜„í™©",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ë…„ ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ëµì  ì‹œì‚¬ì ",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }}
    ]
}}
"""
        
        ai_response = call_llm(prompt)
        
        # AI ì‘ë‹µ íŒŒì‹± (JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ)
        analysis_data = extract_json_from_response(ai_response)
        
        if analysis_data is None:
            analysis_data = {
                'title': 'ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„',
                'sections': [
                    {
                        'sub_title': 'ë¶„ì„ ê²°ê³¼',
                        'ai_text': ai_response
                    }
                ]
            }
        
        # JSON ë°ì´í„° êµ¬ì„±
        json_data = {
            'country': 'CN',
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'key': 'ì¶œê³ ',
            'sub_key': 'ì¹´í…Œê³ ë¦¬ë³„ë§¤ì¶œë¶„ì„',
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'total_records': len(records),
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'raw_data': {
                'sample_records': [dict(r) for r in records[:50]],
                'total_records_count': len(records)
            }
        }
        
        # íŒŒì¼ ì €ì¥
        yyyymm_short = yyyymm[2:]  # 202510 -> 2510
        filename = f"CN_{yyyymm_short}_{brd_cd}_ì¶œê³ _ì¹´í…Œê³ ë¦¬ë³„ë§¤ì¶œë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥
        markdown_content = f"# {analysis_data.get('title', 'ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_agent_store_sales(yyyymm, brd_cd):
    """ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_agent_store_sales_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records if 'SALE_AMT' in r)
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        
        # TODO: ë°ì´í„° ê°€ê³µ ë° ë¶„ì„ ë¡œì§ ì‘ì„±
        
        # AI ë¶„ì„ ìš”ì²­
        prompt = f"""
ë‹¤ìŒì€ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

**ë¶„ì„ ê¸°ê°„**: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”

**ë°ì´í„° ìš”ì•½**:
- ì´ ë§¤ì¶œì•¡: {total_sales/1000000:.2f}ë°±ë§Œì›
- ì´ ë ˆì½”ë“œ ìˆ˜: {len(records)}ê°œ

**ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ** (ìµœëŒ€ 50ê°œ):
{json_dumps_safe([dict(r) for r in records[:50]], ensure_ascii=False, indent=2)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ëŒ€ë¦¬ìƒë³„ ì ë‹¹ë§¤ì¶œ í˜„í™© ë° ì „ë…„ ëŒ€ë¹„ ë³€í™”
2. ì£¼ìš” ëŒ€ë¦¬ìƒì˜ ì„±ê³¼ ë¶„ì„
3. ì „ëµì  ì‹œì‚¬ì  ë° ì•¡ì…˜í”Œëœ

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "title": "ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„",
    "sections": [
        {{
            "sub_title": "ëŒ€ë¦¬ìƒë³„ ì ë‹¹ë§¤ì¶œ í˜„í™©",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ë…„ ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ëµì  ì‹œì‚¬ì ",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }}
    ]
}}
"""
        
        ai_response = call_llm(prompt)
        
        # AI ì‘ë‹µ íŒŒì‹± (JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ)
        analysis_data = extract_json_from_response(ai_response)
        
        if analysis_data is None:
            analysis_data = {
                'title': 'ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„',
                'sections': [
                    {
                        'sub_title': 'ë¶„ì„ ê²°ê³¼',
                        'ai_text': ai_response
                    }
                ]
            }
        
        # JSON ë°ì´í„° êµ¬ì„±
        json_data = {
            'country': 'CN',
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'key': 'ëŒ€ë¦¬ìƒ',
            'sub_key': 'ì ë‹¹ë§¤ì¶œì¢…í•©ë¶„ì„',
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'total_records': len(records),
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'raw_data': {
                'sample_records': [dict(r) for r in records[:50]],
                'total_records_count': len(records)
            }
        }
        
        # íŒŒì¼ ì €ì¥
        yyyymm_short = yyyymm[2:]  # 202510 -> 2510
        filename = f"CN_{yyyymm_short}_{brd_cd}_ëŒ€ë¦¬ìƒ_ì ë‹¹ë§¤ì¶œì¢…í•©ë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥
        markdown_content = f"# {analysis_data.get('title', 'ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_discount_rate(yyyymm, brd_cd):
    """í• ì¸ìœ¨ ì¢…í•©ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"í• ì¸ìœ¨ ì¢…í•©ë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_discount_rate_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records if 'SALE_AMT' in r)
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        
        # TODO: ë°ì´í„° ê°€ê³µ ë° ë¶„ì„ ë¡œì§ ì‘ì„±
        
        # AI ë¶„ì„ ìš”ì²­
        prompt = f"""
ë‹¤ìŒì€ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ í• ì¸ìœ¨ ì¢…í•©ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

**ë¶„ì„ ê¸°ê°„**: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”

**ë°ì´í„° ìš”ì•½**:
- ì´ ë§¤ì¶œì•¡: {total_sales/1000000:.2f}ë°±ë§Œì›
- ì´ ë ˆì½”ë“œ ìˆ˜: {len(records)}ê°œ

**ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ** (ìµœëŒ€ 50ê°œ):
{json_dumps_safe([dict(r) for r in records[:50]], ensure_ascii=False, indent=2)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í• ì¸ìœ¨ í˜„í™© ë° ì „ë…„ ëŒ€ë¹„ ë³€í™”
2. ì±„ë„/ì¹´í…Œê³ ë¦¬ë³„ í• ì¸ìœ¨ ë¶„ì„
3. ì „ëµì  ì‹œì‚¬ì  ë° ì•¡ì…˜í”Œëœ

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "title": "í• ì¸ìœ¨ ì¢…í•©ë¶„ì„",
    "sections": [
        {{
            "sub_title": "í• ì¸ìœ¨ í˜„í™©",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ë…„ ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ëµì  ì‹œì‚¬ì ",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }}
    ]
}}
"""
        
        ai_response = call_llm(prompt)
        
        # AI ì‘ë‹µ íŒŒì‹± (JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ)
        analysis_data = extract_json_from_response(ai_response)
        
        if analysis_data is None:
            analysis_data = {
                'title': 'í• ì¸ìœ¨ ì¢…í•©ë¶„ì„',
                'sections': [
                    {
                        'sub_title': 'ë¶„ì„ ê²°ê³¼',
                        'ai_text': ai_response
                    }
                ]
            }
        
        # JSON ë°ì´í„° êµ¬ì„±
        json_data = {
            'country': 'CN',
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'key': 'í• ì¸ìœ¨',
            'sub_key': 'ì¢…í•©ë¶„ì„',
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'total_records': len(records),
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'raw_data': {
                'sample_records': [dict(r) for r in records[:50]],
                'total_records_count': len(records)
            }
        }
        
        # íŒŒì¼ ì €ì¥
        yyyymm_short = yyyymm[2:]  # 202510 -> 2510
        filename = f"CN_{yyyymm_short}_{brd_cd}_í• ì¸ìœ¨_ì¢…í•©ë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥
        markdown_content = f"# {analysis_data.get('title', 'í• ì¸ìœ¨ ì¢…í•©ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] í• ì¸ìœ¨ ì¢…í•©ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_operating_expense(yyyymm, brd_cd):
    """ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_operating_expense_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_expense = sum(float(r.get('EXPENSE_AMT', 0)) for r in records if 'EXPENSE_AMT' in r)
        print(f"ì´ ì˜ì—…ë¹„: {total_expense:,.0f}ì› ({total_expense/1000000:.2f}ë°±ë§Œì›)")
        
        # TODO: ë°ì´í„° ê°€ê³µ ë° ë¶„ì„ ë¡œì§ ì‘ì„±
        
        # AI ë¶„ì„ ìš”ì²­
        prompt = f"""
ë‹¤ìŒì€ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

**ë¶„ì„ ê¸°ê°„**: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”

**ë°ì´í„° ìš”ì•½**:
- ì´ ì˜ì—…ë¹„: {total_expense/1000000:.2f}ë°±ë§Œì›
- ì´ ë ˆì½”ë“œ ìˆ˜: {len(records)}ê°œ

**ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ** (ìµœëŒ€ 50ê°œ):
{json_dumps_safe([dict(r) for r in records[:50]], ensure_ascii=False, indent=2)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì˜ì—…ë¹„ í˜„í™© ë° ì „ë…„ ëŒ€ë¹„ ë³€í™”
2. ê³„ì •ë³„ ì˜ì—…ë¹„ ë¶„ì„
3. ì „ëµì  ì‹œì‚¬ì  ë° ì•¡ì…˜í”Œëœ

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "title": "ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„",
    "sections": [
        {{
            "sub_title": "ì˜ì—…ë¹„ í˜„í™©",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ë…„ ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }},
        {{
            "sub_title": "ì „ëµì  ì‹œì‚¬ì ",
            "ai_text": "ë¶„ì„ ë‚´ìš©..."
        }}
    ]
}}
"""
        
        ai_response = call_llm(prompt)
        
        # AI ì‘ë‹µ íŒŒì‹± (JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ)
        analysis_data = extract_json_from_response(ai_response)
        
        if analysis_data is None:
            analysis_data = {
                'title': 'ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„',
                'sections': [
                    {
                        'sub_title': 'ë¶„ì„ ê²°ê³¼',
                        'ai_text': ai_response
                    }
                ]
            }
        
        # JSON ë°ì´í„° êµ¬ì„±
        json_data = {
            'country': 'CN',
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'key': 'ì˜ì—…ë¹„',
            'sub_key': 'ì¢…í•©ë¶„ì„',
            'analysis_data': analysis_data,
            'summary': {
                'total_expense': round(total_expense / 1000000, 2),
                'total_records': len(records),
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'raw_data': {
                'sample_records': [dict(r) for r in records[:50]],
                'total_records_count': len(records)
            }
        }
        
        # íŒŒì¼ ì €ì¥
        yyyymm_short = yyyymm[2:]  # 202510 -> 2510
        filename = f"CN_{yyyymm_short}_{brd_cd}_ì˜ì—…ë¹„_ì¢…í•©ë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥
        markdown_content = f"# {analysis_data.get('title', 'ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================
def generate_yyyymm_list(start_yyyymm, end_yyyymm=None):
    """
    ë…„ì›” ë¦¬ìŠ¤íŠ¸ ìƒì„±
    
    Args:
        start_yyyymm: ì‹œì‘ ë…„ì›” (ì˜ˆ: '202401')
        end_yyyymm: ì¢…ë£Œ ë…„ì›” (ì˜ˆ: '202412'). Noneì´ë©´ start_yyyymmë§Œ ë°˜í™˜
    
    Returns:
        list: ë…„ì›” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['202401', '202402', ...])
    """
    if end_yyyymm is None:
        return [start_yyyymm]
    
    start_date = datetime(int(start_yyyymm[:4]), int(start_yyyymm[4:6]), 1)
    end_date = datetime(int(end_yyyymm[:4]), int(end_yyyymm[4:6]), 1)
    
    yyyymm_list = []
    current_date = start_date
    
    while current_date <= end_date:
        yyyymm = current_date.strftime('%Y%m')
        yyyymm_list.append(yyyymm)
        
        # ë‹¤ìŒ ë‹¬ë¡œ ì´ë™
        if current_date.month == 12:
            current_date = datetime(current_date.year + 1, 1, 1)
        else:
            current_date = datetime(current_date.year, current_date.month + 1, 1)
    
    return yyyymm_list

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================
if __name__ == '__main__':
    # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = datetime.now()
    print(f"\n{'='*60}")
    print(f"ë¶„ì„ ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    
    # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”
    reset_token_counter()
    
    # ========================================================================
    # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    # ========================================================================
    # ë°©ë²• 1: í•œ ë‹¬ë§Œ ë¶„ì„
    yyyymm_list = generate_yyyymm_list('202511')
    
    # ë°©ë²• 2: ì—¬ëŸ¬ ë‹¬ ë¶„ì„ (2024ë…„ 1ì›” ~ 2025ë…„ 10ì›”)
    # yyyymm_list = generate_yyyymm_list('202407', '202508')
    
    # ë°©ë²• 3: ì§ì ‘ ë¦¬ìŠ¤íŠ¸ ì§€ì •
    # yyyymm_list = ['202509', '202510', '202511']
    
    if len(yyyymm_list) == 1:
        print(f"ë¶„ì„í•  ê¸°ê°„: {len(yyyymm_list)}ê°œì›” ({yyyymm_list[0]})")
    else:
        print(f"ë¶„ì„í•  ê¸°ê°„: {len(yyyymm_list)}ê°œì›” ({yyyymm_list[0]} ~ {yyyymm_list[-1]})")
    
    # ë¸Œëœë“œ ì„ íƒ (ì›í•˜ëŠ” ë¸Œëœë“œë§Œ ì£¼ì„ í•´ì œ)
    brands_to_analyze = [
        'M',   # MLB
        # 'I',   # MLB KIDS
        # 'X',   # DISCOVERY
        # 'V',   # DUVETICA
        # 'ST',  # SERGIO TACCHINI
        # 'W',   # SUPRA
    ]
    
    # ê¸°ê°„ë³„, ë¸Œëœë“œë³„ ë¶„ì„ ì‹¤í–‰
    for yyyymm in yyyymm_list:
        print(f"\n{'='*60}")
        print(f"ê¸°ê°„ ë¶„ì„ ì‹œì‘: {yyyymm} ({yyyymm[:4]}ë…„ {yyyymm[4:6]}ì›”)")
        print(f"{'='*60}\n")
        
        for brd_cd in brands_to_analyze:
            print(f"\n{'='*60}")
            print(f"ë¸Œëœë“œ ë¶„ì„ ì‹œì‘: {brd_cd} ({BRAND_CODE_MAP.get(brd_cd, brd_cd)})")
            print(f"{'='*60}\n")
            
            try:
                # ë¶„ì„ ì‹¤í–‰ (ì›í•˜ëŠ” ë¶„ì„ë§Œ ì£¼ì„ í•´ì œ)
                analyze_retail_channel_sales(yyyymm, brd_cd)  # ë¦¬í…Œì¼ ì±„ë„ë³„ ë§¤ì¶œë¶„ì„
                # analyze_outbound_category_sales(yyyymm, brd_cd)  # ì¶œê³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œë¶„ì„
                # analyze_agent_store_sales(yyyymm, brd_cd)  # ëŒ€ë¦¬ìƒ ì ë‹¹ë§¤ì¶œ ì¢…í•©ë¶„ì„
                # analyze_discount_rate(yyyymm, brd_cd)  # í• ì¸ìœ¨ ì¢…í•©ë¶„ì„
                # analyze_operating_expense(yyyymm, brd_cd)  # ì˜ì—…ë¹„ ì¢…í•©ë¶„ì„
            except Exception as e:
                print(f"[ERROR] ë¸Œëœë“œ {brd_cd} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"[ERROR] ë‹¤ìŒ ë¸Œëœë“œë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...\n")
                continue
    
    # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
    end_time = datetime.now()
    elapsed_time = end_time - start_time
    
    # í† í° ì‚¬ìš©ëŸ‰ ì¡°íšŒ
    total_tokens = get_total_tokens()
    total_token_count = total_tokens['input'] + total_tokens['output']
    
    print(f"\n{'='*60}")
    print(f"ì „ì²´ ë¸Œëœë“œ ë¶„ì„ ì™„ë£Œ!")
    print(f"ì†Œìš” ì‹œê°„: {elapsed_time}")
    print(f"ì´ í† í° ì‚¬ìš©ëŸ‰: {total_token_count:,} í† í° (ì…ë ¥: {total_tokens['input']:,}, ì¶œë ¥: {total_tokens['output']:,})")
    print(f"{'='*60}\n")

