"""
ê°„ë‹¨í•œ ë¶„ì„ ë„êµ¬ - ëª¨ë“  ê¸°ëŠ¥ì´ í•˜ë‚˜ì˜ íŒŒì¼ì— í†µí•©ë¨
- SQL ì¿¼ë¦¬ ì‹¤í–‰
- LLM í˜¸ì¶œ (Claude)
- Markdown/JSON íŒŒì¼ ì €ì¥
"""

import os
import json
import polars as pl
import anthropic
from datetime import datetime
from sqlalchemy import create_engine
from snowflake.sqlalchemy import URL
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ============================================================================
# ì„¤ì •
# ============================================================================
BRAND_CODE_MAP = {
    'M': 'MLB',
    'I': 'MLB KIDS',
    'X': 'DISCOVERY',
    'V': 'DUVETICA',
    'ST': 'SERGIO TACCHINI',
    'W': 'SUPRA',
}

OUTPUT_JSON_PATH = './output/json'
OUTPUT_MD_PATH = './output/md'

# ì¶œë ¥ í´ë” ìƒì„±
os.makedirs(OUTPUT_JSON_PATH, exist_ok=True)
os.makedirs(OUTPUT_MD_PATH, exist_ok=True)

# ============================================================================
# DB ì—°ê²°
# ============================================================================
def get_db_engine():
    """Snowflake DB ì—°ê²° ì—”ì§„ ìƒì„±"""
    account = os.getenv('SNOWFLAKE_ACCOUNT')
    user = os.getenv('SNOWFLAKE_USER')
    password = os.getenv('SNOWFLAKE_PASSWORD')
    database = os.getenv('SNOWFLAKE_DATABASE')
    schema = os.getenv('SNOWFLAKE_SCHEMA')
    warehouse = os.getenv('SNOWFLAKE_WAREHOUSE')
    role = os.getenv('SNOWFLAKE_ROLE')
    
    if not all([account, user, password, database, schema, warehouse, role]):
        raise ValueError("Snowflake í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    return create_engine(
        URL(
            account=account,
            user=user,
            password=password,
            database=database,
            schema=schema,
            warehouse=warehouse,
            role=role,
        )
    )

# ============================================================================
# SQL ì¿¼ë¦¬ ì‹¤í–‰
# ============================================================================
def run_query(sql, engine):
    """SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ê³  DataFrame ë°˜í™˜"""
    print(f"[SQL] ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
    df = pl.read_database(sql, engine)
    print(f"[OK] {len(df)}ê°œ í–‰ ì¡°íšŒ ì™„ë£Œ")
    return df

# ============================================================================
# LLM í˜¸ì¶œ
# ============================================================================
def call_llm(prompt, max_tokens=4000, temperature=0.7):
    """Claude API í˜¸ì¶œ"""
    api_key = os.getenv('CLAUDE_API_KEY')
    if not api_key:
        raise ValueError("CLAUDE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    client = anthropic.Anthropic(api_key=api_key, timeout=120.0)
    
    system_prompt = """
ë‹¹ì‹ ì€ F&F ê·¸ë£¹ì˜ ìµœê³  ì „ëµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:

ğŸ“Š **ë¶„ì„ ì›ì¹™**
- ìˆ«ìëŠ” ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ê³  ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ëª¨ë“  ê¸ˆì•¡ì€ ë°±ë§Œì› ë‹¨ìœ„ë¡œ í‘œì‹œ (ì›ë³¸ ë°ì´í„°ë¥¼ 1,000,000ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œê¸°)
- ë‹¨ìœ„ëŠ” ë°±ë§Œì›, 3ìë¦¬ë§ˆë‹¤ ì‰¼í‘œ í‘œê¸°
- ë¹„ì¤‘(%)ì€ ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ í‘œí˜„
- ë§¤ì¶œì•¡ì€ act_sale_amt ì»¬ëŸ¼ ì‚¬ìš©í• ê²ƒ ë§¤ì¶œì•¡(v+)ë¼ê³  í‘œí˜„í•˜ê¸°
- í• ì¸ìœ¨ ê³„ì‚°ì€ act_sale_amt / tag_sale_amt ì‚¬ìš©
- ì§ì ‘ì´ìµë¥  ê³„ì‚° ì‹œ ì§ì—…ì´ìµ / (act_sale_amt/1.1) ì‚¬ìš©
- ì˜ì—…ì´ìµë¥  ê³„ì‚° ì‹œ ì˜ì—…ì´ìµ / (act_sale_amt/1.1) ì‚¬ìš©

ğŸ¯ **ë³´ê³  ìŠ¤íƒ€ì¼**
- ê²½ì˜ê´€ë¦¬íŒ€ ëŒ€ìƒì˜ ì „ëµì  ê´€ì 
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì•¡ì…˜í”Œëœ ì œì‹œ
- ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒë¥¼ ëª…í™•íˆ êµ¬ë¶„
- ê·¼ê±° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„
- ì´ìƒì§•í›„ë‚˜ íŠ¹ì´ì‚¬í•­ ì–¸ê¸‰
"""
    
    full_prompt = system_prompt + "\n\n" + prompt
    
    print(f"[LLM] Claude API í˜¸ì¶œ ì¤‘...")
    message = client.messages.create(
        model='claude-sonnet-4-20250514',
        max_tokens=max_tokens,
        temperature=temperature,
        messages=[{"role": "user", "content": full_prompt}]
    )
    print(f"[OK] LLM ì‘ë‹µ ì™„ë£Œ")
    return message.content[0].text

# ============================================================================
# íŒŒì¼ ì €ì¥
# ============================================================================
def save_markdown(content, filename):
    """Markdown íŒŒì¼ ì €ì¥"""
    file_path = os.path.join(OUTPUT_MD_PATH, f"{filename}.md")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"[OK] Markdown ì €ì¥: {file_path}")
    return file_path

def save_json(data, filename):
    """JSON íŒŒì¼ ì €ì¥"""
    file_path = os.path.join(OUTPUT_JSON_PATH, f"{filename}.json")
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"[OK] JSON ì €ì¥: {file_path}")
    return file_path

# ============================================================================
# SQL ì¿¼ë¦¬ ì˜ˆì‹œ
# ============================================================================
def get_channel_sales_cypy_query(yyyymm, yyyymm_py, brd_cd):
    """ì±„ë„ë³„ ë§¤ì¶œ top3 ë¶„ì„ ì¿¼ë¦¬ (ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ) - 4-1-1-1ìš©"""
    return f"""
    WITH raw AS (
        SELECT pst_yyyymm,
               CASE 
                   WHEN b.mgmt_chnl_cd = '4' THEN 'ìì‚¬ëª°'
                   WHEN b.mgmt_chnl_cd = '5' THEN 'ì œíœ´ëª°'
                   WHEN b.mgmt_chnl_cd IN ('3', '11', 'C3') THEN 'ì§ì˜ì '
                   WHEN b.mgmt_chnl_nm LIKE 'ì•„ìš¸ë ›%' THEN 'ì•„ìš¸ë ›'
                   ELSE b.mgmt_chnl_nm
               END AS chnl_nm,
               c.prdt_hrrc3_nm AS class3,
               SUM(a.act_sale_amt) AS sale_amt
        FROM sap_fnf.dm_pl_shop_prdt_m a
        JOIN sap_fnf.mst_shop b 
            ON a.brd_cd = b.brd_cd
           AND a.shop_cd = b.sap_shop_cd
        JOIN sap_fnf.mst_prdt c
            ON a.prdt_cd = c.prdt_cd
        WHERE 1=1
          AND a.corp_cd = '1000'
          AND a.brd_cd = '{brd_cd}'
          AND a.chnl_cd NOT IN ('0', '8', '9', '99')
          AND a.pst_yyyymm IN ('{yyyymm}', '{yyyymm_py}')
        GROUP BY 1, 2, 3
    ), main AS (
        SELECT pst_yyyymm,
               chnl_nm,
               class3,
               sale_amt,
               sale_amt_chnl_ttl,
               DENSE_RANK() OVER(PARTITION BY pst_yyyymm ORDER BY sale_amt_chnl_ttl DESC) AS in_yymm_rnk,
               DENSE_RANK() OVER(PARTITION BY pst_yyyymm, chnl_nm ORDER BY sale_amt DESC) AS in_chnl_rnk
        FROM (
            SELECT pst_yyyymm,
                   chnl_nm,
                   class3,
                   sale_amt,
                   SUM(sale_amt) OVER(PARTITION BY pst_yyyymm, chnl_nm) AS sale_amt_chnl_ttl
            FROM raw
        )
    )
    SELECT pst_yyyymm,
           chnl_nm,
           class3,
           sale_amt,
           sale_amt_chnl_ttl,
           CASE WHEN sale_amt_chnl_ttl = 0 THEN 0 ELSE ROUND(sale_amt / sale_amt_chnl_ttl * 100) END AS sale_ratio,
           in_yymm_rnk,
           in_chnl_rnk
    FROM main 
    ORDER BY pst_yyyymm DESC, in_yymm_rnk, in_chnl_rnk
    """

def get_channel_sales_query(yyyymm_start, yyyymm_end, brd_cd):
    """ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ ì¿¼ë¦¬ (12ê°œì›” ì¶”ì´)"""
    return f"""
    WITH raw AS (
        SELECT pst_yyyymm,
               CASE 
                   WHEN b.mgmt_chnl_cd = '4' THEN 'ìì‚¬ëª°'
                   WHEN b.mgmt_chnl_cd = '5' THEN 'ì œíœ´ëª°'
                   WHEN b.mgmt_chnl_cd IN ('3', '11', 'C3') THEN 'ì§ì˜ì '
                   WHEN b.mgmt_chnl_nm LIKE 'ì•„ìš¸ë ›%' THEN 'ì•„ìš¸ë ›'
                   ELSE b.mgmt_chnl_nm
               END AS chnl_nm,
               c.prdt_hrrc3_nm AS class3,
               SUM(a.act_sale_amt) AS sale_amt
        FROM sap_fnf.dm_pl_shop_prdt_m a
        JOIN sap_fnf.mst_shop b 
            ON a.brd_cd = b.brd_cd
           AND a.shop_cd = b.sap_shop_cd
        JOIN sap_fnf.mst_prdt c
            ON a.prdt_cd = c.prdt_cd
        WHERE 1=1
          AND a.corp_cd = '1000'
          AND a.brd_cd = '{brd_cd}'
          AND a.chnl_cd NOT IN ('0', '8', '9', '99')
          AND a.pst_yyyymm BETWEEN '{yyyymm_start}' AND '{yyyymm_end}'
        GROUP BY 1, 2, 3
    ), main AS (
        SELECT pst_yyyymm,
               chnl_nm,
               class3,
               sale_amt,
               sale_amt_chnl_ttl,
               DENSE_RANK() OVER(PARTITION BY pst_yyyymm ORDER BY sale_amt_chnl_ttl DESC) AS in_yymm_rnk,
               DENSE_RANK() OVER(PARTITION BY pst_yyyymm, chnl_nm ORDER BY sale_amt DESC) AS in_chnl_rnk
        FROM (
            SELECT pst_yyyymm,
                   chnl_nm,
                   class3,
                   sale_amt,
                   SUM(sale_amt) OVER(PARTITION BY pst_yyyymm, chnl_nm) AS sale_amt_chnl_ttl
            FROM raw
        )
    )
    SELECT pst_yyyymm,
           chnl_nm,
           class3,
           sale_amt,
           sale_amt_chnl_ttl,
           CASE WHEN sale_amt_chnl_ttl = 0 THEN 0 ELSE ROUND(sale_amt / sale_amt_chnl_ttl * 100) END AS sale_ratio,
           in_yymm_rnk,
           in_chnl_rnk
    FROM main 
    ORDER BY pst_yyyymm DESC, in_yymm_rnk, in_chnl_rnk
    """

def get_ad_expense_detail_query(yyyymm, yyyymm_py, brd_cd):
    """ê´‘ê³ ì„ ì „ë¹„ ë‹¹í•´/ì „ë…„ ì„¸ë¶€ ë‚´ì—­ ì¿¼ë¦¬"""
    return f"""
    SELECT PST_YYYYMM, CTGR1, CTGR2, CTGR3, GL_NM, SUM(TTL_USE_AMT) AS AD_TTL_AMT
    FROM SAP_FNF.DM_IDCST_CCTR_M
    WHERE BRD_CD = '{brd_cd}'
      AND PST_YYYYMM = '{yyyymm}'
      AND CTGR1 = 'ê´‘ê³ ì„ ì „ë¹„'
    GROUP BY PST_YYYYMM, BRD_NM, CTGR1, CTGR2, CTGR3, GL_NM
    
    UNION ALL
    
    SELECT PST_YYYYMM, CTGR1, CTGR2, CTGR3, GL_NM, SUM(TTL_USE_AMT) AS AD_TTL_AMT
    FROM SAP_FNF.DM_IDCST_CCTR_M
    WHERE BRD_CD = '{brd_cd}'
      AND PST_YYYYMM = '{yyyymm_py}'
      AND CTGR1 = 'ê´‘ê³ ì„ ì „ë¹„'
    GROUP BY PST_YYYYMM, BRD_NM, CTGR1, CTGR2, CTGR3, GL_NM
    ORDER BY AD_TTL_AMT DESC
    """

def get_ad_expense_trend_query(trend_months, brd_cd):
    """ê´‘ê³ ì„ ì „ë¹„ 12ê°œì›” ì¶”ì„¸ ì„¸ë¶€ ë‚´ì—­ ì¿¼ë¦¬"""
    trend_months_str = "', '".join(trend_months)
    return f"""
    SELECT PST_YYYYMM,
           CTGR2,
           CTGR3,
           GL_NM,
           SUM(TTL_USE_AMT) AS TTL_USE_AMT
    FROM SAP_FNF.DM_IDCST_CCTR_M
    WHERE PST_YYYYMM IN ('{trend_months_str}')
      AND CTGR1 = 'ê´‘ê³ ì„ ì „ë¹„'
      AND BRD_CD = '{brd_cd}'
    GROUP BY PST_YYYYMM, CTGR2, CTGR3, GL_NM
    ORDER BY PST_YYYYMM, TTL_USE_AMT DESC
    """

# ============================================================================
# ë¶„ì„ í•¨ìˆ˜
# ============================================================================
def analyze_channel_sales(yyyymm, brd_cd):
    """ì±„ë„ë³„_ë§¤ì¶œ_top3_ë¶„ì„(ë‹¹í•´_ì „ë…„_ì£¼ìš”ë³€í™”)"""
    print(f"\n{'='*60}")
    print(f"ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (ë‹¹í•´/ì „ë…„ ë™ì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰ (4-1-1-1ìš©: ë‹¹í•´/ì „ë…„ ë™ì›” ë¹„êµ)
        sql = get_channel_sales_cypy_query(yyyymm, yyyymm_py, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records)
        unique_channels = len(set(r.get('CHNL_NM', '') for r in records))
        unique_items = len(set(r.get('CLASS3', '') for r in records))
        unique_months = len(set(r.get('PST_YYYYMM', '') for r in records))
        
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        print(f"ì±„ë„ ìˆ˜: {unique_channels}ê°œ")
        print(f"ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ")
        print(f"ë¶„ì„ ì›” ìˆ˜: {unique_months}ê°œì›”")
        
        # ì±„ë„ë³„ ìš”ì•½ ë°ì´í„° ìƒì„±
        channel_summary = {}
        for record in records:
            chnl_nm = record.get('CHNL_NM', 'ê¸°íƒ€')
            month = record.get('PST_YYYYMM', '')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            if chnl_nm not in channel_summary:
                channel_summary[chnl_nm] = {
                    'total_sales': 0,
                    'months': {},
                    'top_items': []
                }
            
            channel_summary[chnl_nm]['total_sales'] += sale_amt
            
            if month not in channel_summary[chnl_nm]['months']:
                channel_summary[chnl_nm]['months'][month] = 0
            channel_summary[chnl_nm]['months'][month] += sale_amt
        
        # ì±„ë„ë³„ ìƒìœ„ ì•„ì´í…œ ì¶”ì¶œ
        item_sales_by_channel = {}
        for record in records:
            chnl_nm = record.get('CHNL_NM', 'ê¸°íƒ€')
            class3 = record.get('CLASS3', 'ê¸°íƒ€')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            key = f"{chnl_nm}|{class3}"
            if key not in item_sales_by_channel:
                item_sales_by_channel[key] = {
                    'chnl_nm': chnl_nm,
                    'class3': class3,
                    'total_sales': 0
                }
            item_sales_by_channel[key]['total_sales'] += sale_amt
        
        # ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œ ì•„ì´í…œ ì¶”ì¶œ
        for chnl_nm in channel_summary.keys():
            channel_items = [
                item for key, item in item_sales_by_channel.items()
                if item['chnl_nm'] == chnl_nm
            ]
            channel_items.sort(key=lambda x: x['total_sales'], reverse=True)
            channel_summary[chnl_nm]['top_items'] = [
                {
                    'class3': item['class3'],
                    'total_sales': round(item['total_sales'] / 1000000, 2)
                }
                for item in channel_items[:5]
            ]
            channel_summary[chnl_nm]['total_sales'] = round(
                channel_summary[chnl_nm]['total_sales'] / 1000000, 2
            )
        
        # ì›”ë³„ í•©ê³„ ê³„ì‚°
        monthly_totals = {}
        for record in records:
            month = record.get('PST_YYYYMM', '')
            sale_amt = float(record.get('SALE_AMT', 0))
            if month not in monthly_totals:
                monthly_totals[month] = 0
            monthly_totals[month] += sale_amt
        
        monthly_totals_list = [
            {'yyyymm': month, 'total_amount': round(amount / 1000000, 2)}
            for month, amount in sorted(monthly_totals.items())
        ]
        
        # ì±„ë„ë³„ë¡œ ë‹¹í•´/ì „ë…„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        channel_data_check = {}
        for record in records:
            chnl_nm = record.get('CHNL_NM', 'ê¸°íƒ€')
            month = record.get('PST_YYYYMM', '')
            
            if chnl_nm not in channel_data_check:
                channel_data_check[chnl_nm] = {
                    'has_current': False,
                    'has_previous': False
                }
            
            if month == yyyymm:
                channel_data_check[chnl_nm]['has_current'] = True
            elif month == yyyymm_py:
                channel_data_check[chnl_nm]['has_previous'] = True
        
        # ë‹¹í•´/ì „ë…„ ë°ì´í„°ê°€ ëª¨ë‘ ìˆëŠ” ì±„ë„ë§Œ í•„í„°ë§
        valid_channels = [
            chnl for chnl, check in channel_data_check.items()
            if check['has_current'] and check['has_previous']
        ]
        
        # ì±„ë„ë³„ ë°ì´í„° ìš”ì•½ (ë‹¹í•´/ì „ë…„ ë¹„êµìš©)
        channel_comparison = {}
        for chnl_nm in valid_channels:
            current_data = [r for r in records if r.get('CHNL_NM') == chnl_nm and r.get('PST_YYYYMM') == yyyymm]
            previous_data = [r for r in records if r.get('CHNL_NM') == chnl_nm and r.get('PST_YYYYMM') == yyyymm_py]
            
            # ì±„ë„ë³„ TOP 3 ì•„ì´í…œ (ë‹¹í•´ ê¸°ì¤€)
            current_items = sorted(current_data, key=lambda x: float(x.get('SALE_AMT', 0)), reverse=True)[:3]
            
            channel_comparison[chnl_nm] = {
                'current_top3': [
                    {
                        'class3': item.get('CLASS3', ''),
                        'sale_amt': round(float(item.get('SALE_AMT', 0)) / 1000000, 2),
                        'sale_ratio': float(item.get('SALE_RATIO', 0))
                    }
                    for item in current_items
                ],
                'current_total': round(sum(float(r.get('SALE_AMT', 0)) for r in current_data) / 1000000, 2),
                'previous_total': round(sum(float(r.get('SALE_AMT', 0)) for r in previous_data) / 1000000, 2)
            }
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (JSON í˜•ì‹ ì‘ë‹µ ìš”ì²­)
        prompt = f"""
ë„ˆëŠ” F&F ê·¸ë£¹ì˜ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œ ì±„ë„ ì „ëµ ì „ë¬¸ê°€ì•¼. ê° ì±„ë„ë³„ ë‹¹í•´ ë‹¹ì›” ë§¤ì¶œ ë² ìŠ¤íŠ¸ ì•„ì´í…œ 3ê°œë¥¼ ì „ë…„ëŒ€ë¹„ ì£¼ìš”ë³€í™”ë¡œ ë¶„ì„í•´ì¤˜.

**ë¶„ì„ ê¸°ê°„**
- ë‹¹í•´: {current_year}ë…„ {current_month}ì›” ({yyyymm})
- ì „ë…„: {previous_year}ë…„ {current_month}ì›” ({yyyymm_py})

**ì „ì²´ ìš”ì•½**
- ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)
- ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ ìˆ˜: {len(valid_channels)}ê°œ
- ë¶„ì„ ì±„ë„ ëª©ë¡: {', '.join(valid_channels)}
- ë¶„ì„ ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ

**ì±„ë„ë³„ ë°ì´í„° ìš”ì•½**
{json.dumps(channel_comparison, ensure_ascii=False, indent=2)}

<ë¶„ì„ ëª©í‘œ>
{BRAND_CODE_MAP.get(brd_cd, brd_cd)} ê° ì±„ë„ë³„ ë‹¹í•´ ë‹¹ì›” ë§¤ì¶œ ë² ìŠ¤íŠ¸ ì•„ì´í…œ 3ê°œë¥¼ ì „ë…„ëŒ€ë¹„ ì£¼ìš”ë³€í™”ë¡œ ë¶„ì„í•´ì¤˜.

**ì¤‘ìš”**: ìœ„ "ì±„ë„ë³„ ë°ì´í„° ìš”ì•½"ì— ìˆëŠ” ì±„ë„ë§Œ ë¶„ì„í•˜ë©´ ë©ë‹ˆë‹¤. ë°ì´í„°ê°€ ì—†ëŠ” ì±„ë„ì€ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”.

<ë°ì´í„° ìƒ˜í”Œ>
{json.dumps(records[:200], ensure_ascii=False, indent=2)}

<ìš”êµ¬ì‚¬í•­>
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•´ì¤˜.

ê° ì±„ë„ë³„ë¡œ í•˜ë‚˜ì˜ ì„¹ì…˜ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì±„ë„ ëª©ë¡: {', '.join(valid_channels)}

{{
  "title": "ì±„ë„ë³„ ë§¤ì¶œ top3 ë¶„ì„ (ë‹¹í•´ ì „ë…„ ì£¼ìš”ë³€í™”)",
  "sections": [
    {{
      "sub_title": "{{ì±„ë„ëª…}} ì „ë…„ëŒ€ë¹„ ì£¼ìš” ë³€í™”",
      "ai_text": "ê° {{ì±„ë„ëª…}} ë‹¹í•´ ë‹¹ì›” ë§¤ì¶œ ë² ìŠ¤íŠ¸ ì•„ì´í…œ 3ê°œë¥¼ í•œ ì¤„ì”© ì „ë…„ëŒ€ë¹„ ì£¼ìš”ë³€í™”ë¡œ ë¶„ì„í•´ì¤˜. ì±„ë„ë³„ ë°ì´í„° ìš”ì•½ì˜ current_top3ì™€ current_total, previous_totalì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì¸ ë³€í™”ìœ¨ê³¼ ì›ì¸ì„ ë¶„ì„í•´ì¤˜. (ì˜ˆ: â€¢ ìš´ë™ëª¨: ë‹¹í•´ ì‹ ê·œ Dí• ì–¸ìŠ¤íŠ¸ëŸ­ì³ ë³¼ìº¡ ì œí’ˆ +156.3% í­ì¦\\n â€¢ ìˆ„ë”ë°±: í´ë˜ì‹ ëª¨ë…¸ê·¸ë¨ ë‰´ ì— ë³´ ì„±ìˆ˜/í•œë‚¨ì  í­ë°œì  ë°˜ì‘ +145.2%\\n â€¢ í–‡ : ê³ ë”•ë²„í‚·í–‡ ì œí’ˆ í­ë°œì  ì„±ì¥ +120.1% ë“±)"
    }}
  ]
}}

<ì‘ì„± ê°€ì´ë“œë¼ì¸>
- ê° ì„¹ì…˜ì˜ ai_textëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
- ìˆ«ìëŠ” ë°±ë§Œì› ë‹¨ìœ„ë¡œ í‘œì‹œí•˜ê³  ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ ê²ƒ
- ë‹¹í•´ ì±„ë„ë³„ TOP 3 ë§¤ì¶œ ì•„ì´í…œê³¼ ê·¸ì¤‘ ì–´ë–¤ ì œí’ˆì´ íŒë§¤ìœ¨ì´ ì¢‹ì•˜ëŠ”ì§€
- ì „ë…„ëŒ€ë¹„ ì£¼ìš” ë³€í™” ë¶„ì„
- ë‹¨ê¸° ì „ëµ ë°©í–¥ê³¼ ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‹œì‚¬
- ë¶ˆë¦¿ í¬ì¸íŠ¸ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹(-, â€¢) ì‚¬ìš© ê°€ëŠ¥
- ì¤„ë°”ê¿ˆì€ ë°˜ë“œì‹œ \\nì„ ì‚¬ìš©í•˜ì—¬ í‘œì‹œ (ì˜ˆ: "ì²« ë²ˆì§¸ ì¤„\\në‘ ë²ˆì§¸ ì¤„")
- ai_text ë‚´ì—ì„œ ì—¬ëŸ¬ ë¬¸ë‹¨ì´ë‚˜ í•­ëª©ì„ ë‚˜ëˆŒ ë•ŒëŠ” \\n\\nì„ ì‚¬ìš©
- ë¶ˆë¦¿ í¬ì¸íŠ¸ë‚˜ ë¦¬ìŠ¤íŠ¸ í•­ëª© ì‚¬ì´ì—ëŠ” \\nì„ ì‚¬ìš©
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´)

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜:
"""
        
        # LLM í˜¸ì¶œ (JSON ì‘ë‹µ)
        analysis_response = call_llm(prompt, max_tokens=4000)
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        analysis_response = analysis_response.strip()
        if analysis_response.startswith('```json'):
            analysis_response = analysis_response[7:]
        if analysis_response.startswith('```'):
            analysis_response = analysis_response[3:]
        if analysis_response.endswith('```'):
            analysis_response = analysis_response[:-3]
        analysis_response = analysis_response.strip()
        
        try:
            analysis_data = json.loads(analysis_response)
        except json.JSONDecodeError as e:
            print(f"[WARNING] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"[WARNING] ì‘ë‹µ ë‚´ìš©: {analysis_response[:500]}")
            # ê¸°ë³¸ êµ¬ì¡°ë¡œ ëŒ€ì²´
            analysis_data = {
                "title": "ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ (12ê°œì›” ì¶”ì´)",
                "sections": [
                    {"sub_title": "ë¶„ì„ ê²°ê³¼", "ai_text": analysis_response}
                ]
            }
        
        # JSON ë°ì´í„° ìƒì„±
        json_data = {
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm': yyyymm,
            'yyyymm_py': yyyymm_py,
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'unique_channels': unique_channels,
                'unique_items': unique_items,
                'unique_months': unique_months,
                'analysis_period': f"{previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”"
            },
            'channel_summary': channel_summary,
            'raw_data': {
                'sample_records': [
                    {
                        'PST_YYYYMM': r.get('PST_YYYYMM', ''),
                        'CHNL_NM': r.get('CHNL_NM', ''),
                        'CLASS3': r.get('CLASS3', ''),
                        'SALE_AMT': float(r.get('SALE_AMT', 0)),
                        'SALE_AMT_CHNL_TTL': float(r.get('SALE_AMT_CHNL_TTL', 0)),
                        'SALE_RATIO': float(r.get('SALE_RATIO', 0)),
                        'IN_YMM_RNK': int(r.get('IN_YMM_RNK', 0)),
                        'IN_CHNL_RNK': int(r.get('IN_CHNL_RNK', 0))
                    }
                    for r in records[:50]
                ],
                'total_records_count': len(records)
            },
            'trend_data': {
                'trend_months': sorted(list(set(r.get('PST_YYYYMM', '') for r in records))),
                'monthly_totals': monthly_totals_list,
                'monthly_details': [
                    {
                        'yyyymm': r.get('PST_YYYYMM', ''),
                        'chnl_nm': r.get('CHNL_NM', ''),
                        'class3': r.get('CLASS3', ''),
                        'sale_amt': round(float(r.get('SALE_AMT', 0)) / 1000000, 2),
                        'sale_ratio': float(r.get('SALE_RATIO', 0))
                    }
                    for r in records
                ]
            }
        }
        
        # íŒŒì¼ ì €ì¥
        filename = f"4-1-1-1.{brd_cd}_ì±„ë„ë³„_ë§¤ì¶œ_top3_ë¶„ì„(ë‹¹í•´_ì „ë…„_ì£¼ìš”ë³€í™”)"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥ (analysis_dataì˜ sectionsë¥¼ ì¡°í•©)
        markdown_content = f"# {analysis_data.get('title', 'ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_channel_sales_overall(yyyymm, brd_cd): 
    """ì±„ë„ë³„ ë§¤ì¶œ ì¢…í•©ë¶„ì„ (12ê°œì›” ì¶”ì´) - 4-1-1-2"""
    print(f"\n{'='*60}")
    print(f"ì±„ë„ë³„ ë§¤ì¶œ ì¢…í•©ë¶„ì„ ì‹œì‘ (4-1-1-2): {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ë¶„ì„ ê¸°ê°„ ê³„ì‚° (12ê°œì›”)
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        
        start_year = current_year
        start_month = current_month - 11
        
        while start_month <= 0:
            start_month += 12
            start_year -= 1
        
        yyyymm_start = f"{start_year:04d}{start_month:02d}"
        yyyymm_end = yyyymm
        
        print(f"ë¶„ì„ ê¸°ê°„: {yyyymm_start[:4]}ë…„ {yyyymm_start[4:6]}ì›” ~ {yyyymm_end[:4]}ë…„ {yyyymm_end[4:6]}ì›”")
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        sql = get_channel_sales_query(yyyymm_start, yyyymm_end, brd_cd)
        df = run_query(sql, engine)
        records = df.to_dicts()
        
        if not records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ìš”ì•½
        total_sales = sum(float(r.get('SALE_AMT', 0)) for r in records)
        unique_channels = len(set(r.get('CHNL_NM', '') for r in records))
        unique_items = len(set(r.get('CLASS3', '') for r in records))
        unique_months = len(set(r.get('PST_YYYYMM', '') for r in records))
        
        print(f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)")
        print(f"ì±„ë„ ìˆ˜: {unique_channels}ê°œ")
        print(f"ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ")
        print(f"ë¶„ì„ ì›” ìˆ˜: {unique_months}ê°œì›”")
        
        # ì±„ë„ë³„ ìš”ì•½ ë°ì´í„° ìƒì„±
        channel_summary = {}
        for record in records:
            chnl_nm = record.get('CHNL_NM', 'ê¸°íƒ€')
            month = record.get('PST_YYYYMM', '')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            if chnl_nm not in channel_summary:
                channel_summary[chnl_nm] = {
                    'total_sales': 0,
                    'months': {},
                    'top_items': []
                }
            
            channel_summary[chnl_nm]['total_sales'] += sale_amt
            
            if month not in channel_summary[chnl_nm]['months']:
                channel_summary[chnl_nm]['months'][month] = 0
            channel_summary[chnl_nm]['months'][month] += sale_amt
        
        # ì±„ë„ë³„ ìƒìœ„ ì•„ì´í…œ ì¶”ì¶œ
        item_sales_by_channel = {}
        for record in records:
            chnl_nm = record.get('CHNL_NM', 'ê¸°íƒ€')
            class3 = record.get('CLASS3', 'ê¸°íƒ€')
            sale_amt = float(record.get('SALE_AMT', 0))
            
            key = f"{chnl_nm}|{class3}"
            if key not in item_sales_by_channel:
                item_sales_by_channel[key] = {
                    'chnl_nm': chnl_nm,
                    'class3': class3,
                    'total_sales': 0
                }
            item_sales_by_channel[key]['total_sales'] += sale_amt
        
        # ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œ ì•„ì´í…œ ì¶”ì¶œ
        for chnl_nm in channel_summary.keys():
            channel_items = [
                item for key, item in item_sales_by_channel.items()
                if item['chnl_nm'] == chnl_nm
            ]
            channel_items.sort(key=lambda x: x['total_sales'], reverse=True)
            channel_summary[chnl_nm]['top_items'] = [
                {
                    'class3': item['class3'],
                    'total_sales': round(item['total_sales'] / 1000000, 2)
                }
                for item in channel_items[:5]
            ]
            channel_summary[chnl_nm]['total_sales'] = round(
                channel_summary[chnl_nm]['total_sales'] / 1000000, 2
            )
        
        # ì›”ë³„ í•©ê³„ ê³„ì‚°
        monthly_totals = {}
        for record in records:
            month = record.get('PST_YYYYMM', '')
            sale_amt = float(record.get('SALE_AMT', 0))
            if month not in monthly_totals:
                monthly_totals[month] = 0
            monthly_totals[month] += sale_amt
        
        monthly_totals_list = [
            {'yyyymm': month, 'total_amount': round(amount / 1000000, 2)}
            for month, amount in sorted(monthly_totals.items())
        ]
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (JSON í˜•ì‹ ì‘ë‹µ ìš”ì²­)
        prompt = f"""
ë„ˆëŠ” F&F ê·¸ë£¹ì˜ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œ ì±„ë„ ì „ëµ ì „ë¬¸ê°€ì•¼. 12ê°œì›”ê°„ì˜ ì±„ë„ë³„ ë§¤ì¶œ ì¶”ì´ë¥¼ ë¶„ì„í•˜ì—¬ ì±„ë„ë³„ ì„±ê³¼ì™€ ì•„ì´í…œ í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµì„ ì œì‹œí•´ì•¼ í•´.

**ë¶„ì„ ê¸°ê°„**
- ì‹œì‘: {yyyymm_start[:4]}ë…„ {yyyymm_start[4:6]}ì›”
- ì¢…ë£Œ: {yyyymm_end[:4]}ë…„ {yyyymm_end[4:6]}ì›”
- ê¸°ê°„: {unique_months}ê°œì›”

**ì „ì²´ ìš”ì•½**
- ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì› ({total_sales/1000000:.2f}ë°±ë§Œì›)
- ë¶„ì„ ì±„ë„ ìˆ˜: {unique_channels}ê°œ
- ë¶„ì„ ì•„ì´í…œ ìˆ˜: {unique_items}ê°œ

<ë¶„ì„ ëª©í‘œ>
{BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ 12ê°œì›”ê°„ ì±„ë„ë³„ ë§¤ì¶œ ì¶”ì´ë¥¼ ë¶„ì„í•˜ì—¬:
1. ì±„ë„ë³„ ì„±ê³¼ì™€ ì„±ì¥ íŒ¨í„´ íŒŒì•…
2. ì±„ë„ë³„ í•µì‹¬ ì•„ì´í…œ(í´ë˜ìŠ¤3) ì‹ë³„
3. ì±„ë„ë³„ ë§¤ì¶œ ê¸°ì—¬ë„ì™€ ë¹„ì¤‘ ë¶„ì„
4. ì±„ë„ë³„ ì „ëµì  ì¸ì‚¬ì´íŠ¸ ì œì‹œ

<ë°ì´í„° ìƒ˜í”Œ>
{json.dumps(records[:100], ensure_ascii=False, indent=2)}

<ìš”êµ¬ì‚¬í•­>
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•´ì¤˜.

{{
  "title": "ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ (12ê°œì›” ì¶”ì´)",
  "sections": [
    {{
      "sub_title": "ì±„ë„ë³„ ì„±ê³¼ ì¢…í•© í‰ê°€",
      "ai_text": "12ê°œì›”ê°„ì˜ ì±„ë„ë³„ ë§¤ì¶œ ì„±ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•œ ë‚´ìš© (ì˜ˆ: ìì‚¬ëª°ì´ ì „ì²´ ë§¤ì¶œì˜ 45%ë¥¼ ì°¨ì§€í•˜ë©° í•µì‹¬ ì±„ë„ë¡œ ë¶€ìƒ, ì§ì˜ì ì€ ì•ˆì •ì  ì„±ì¥ì„¸ ìœ ì§€ ë“±)"
    }},
    {{
      "sub_title": "ì„±ì¥ ì±„ë„ ë° ê¸°íšŒ",
      "ai_text": "ì„±ì¥ì„¸ê°€ ëšœë ·í•œ ì±„ë„ê³¼ ê¸°íšŒë¥¼ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë‚˜ì—´ (ì˜ˆ: â€¢ ìì‚¬ëª°: 12ê°œì›”ê°„ ì§€ì†ì  ì„±ì¥ìœ¼ë¡œ ì „ì²´ ë§¤ì¶œì˜ 45% ê¸°ì—¬ ë“±)"
    }},
    {{
      "sub_title": "ì£¼ì˜ í•„ìš” ì±„ë„",
      "ai_text": "ì£¼ì˜ê°€ í•„ìš”í•œ ì±„ë„ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë‚˜ì—´ (ì˜ˆ: â€¢ ì œíœ´ëª°: ìµœê·¼ 3ê°œì›”ê°„ ë§¤ì¶œ ê°ì†Œ ì¶”ì„¸ ë“±)"
    }},
    {{
      "sub_title": "ì´ìƒì§•í›„ ë° ë¦¬ìŠ¤í¬ ê°ì§€",
      "ai_text": "ì´ìƒì§•í›„ì™€ ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª… (ì˜ˆ: â€¢ íŠ¹ì • ì±„ë„ì˜ ì•„ì´í…œ ì§‘ì¤‘ë„ ê³¼ë‹¤: ìì‚¬ëª°ì˜ ìƒìœ„ 3ê°œ ì•„ì´í…œì´ ì „ì²´ì˜ 60% ì°¨ì§€ ë“±)"
    }},
    {{
      "sub_title": "ì±„ë„ë³„ ì „ëµ ìµœì í™” ë°©ì•ˆ",
      "ai_text": "ë‹¨ê¸° ì „ëµ ë°©í–¥ê³¼ ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ (ì˜ˆ: ### ì¦‰ì‹œ ì‹¤í–‰ ë°©ì•ˆ\\n1. ìì‚¬ëª° ì•„ì´í…œ í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ë³€í™”: ... ë“±)"
    }}
  ]
}}

<ì‘ì„± ê°€ì´ë“œë¼ì¸>
- ê° ì„¹ì…˜ì˜ ai_textëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
- ìˆ«ìëŠ” ë°±ë§Œì› ë‹¨ìœ„ë¡œ í‘œì‹œí•˜ê³  ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ ê²ƒ
- ëª¨ë“  ê´‘ê³ ì„ ì „ë¹„ ê³„ì • (CTGR3) ëˆ„ë½ ì—†ì´ ë¶„ì„
- ì „ë…„ëŒ€ë¹„ ë³€í™”ì— ëŒ€í•œ êµ¬ì²´ì  ì›ì¸ê³¼ íš¨ê³¼ ë¶„ì„
- ë‹¨ê¸° ì „ëµ ë°©í–¥ê³¼ ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ë¶ˆë¦¿ í¬ì¸íŠ¸ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹(-, â€¢) ì‚¬ìš© ê°€ëŠ¥
- ì¤„ë°”ê¿ˆì€ ë°˜ë“œì‹œ \\nì„ ì‚¬ìš©í•˜ì—¬ í‘œì‹œ (ì˜ˆ: "ì²« ë²ˆì§¸ ì¤„\\në‘ ë²ˆì§¸ ì¤„")
- ai_text ë‚´ì—ì„œ ì—¬ëŸ¬ ë¬¸ë‹¨ì´ë‚˜ í•­ëª©ì„ ë‚˜ëˆŒ ë•ŒëŠ” \\n\\nì„ ì‚¬ìš©
- ë¶ˆë¦¿ í¬ì¸íŠ¸ë‚˜ ë¦¬ìŠ¤íŠ¸ í•­ëª© ì‚¬ì´ì—ëŠ” \\nì„ ì‚¬ìš©
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´)

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜:
"""
        
        # LLM í˜¸ì¶œ (JSON ì‘ë‹µ)
        analysis_response = call_llm(prompt, max_tokens=4000)
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        analysis_response = analysis_response.strip()
        if analysis_response.startswith('```json'):
            analysis_response = analysis_response[7:]
        if analysis_response.startswith('```'):
            analysis_response = analysis_response[3:]
        if analysis_response.endswith('```'):
            analysis_response = analysis_response[:-3]
        analysis_response = analysis_response.strip()
        
        try:
            analysis_data = json.loads(analysis_response)
        except json.JSONDecodeError as e:
            print(f"[WARNING] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"[WARNING] ì‘ë‹µ ë‚´ìš©: {analysis_response[:500]}")
            # ê¸°ë³¸ êµ¬ì¡°ë¡œ ëŒ€ì²´
            analysis_data = {
                "title": "ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ (12ê°œì›” ì¶”ì´)",
                "sections": [
                    {"sub_title": "ë¶„ì„ ê²°ê³¼", "ai_text": analysis_response}
                ]
            }
        
        # JSON ë°ì´í„° ìƒì„±
        json_data = {
            'brand_cd': brd_cd,
            'brand_name': BRAND_CODE_MAP.get(brd_cd, brd_cd),
            'yyyymm_start': yyyymm_start,
            'yyyymm_end': yyyymm_end,
            'analysis_data': analysis_data,
            'summary': {
                'total_sales': round(total_sales / 1000000, 2),
                'unique_channels': unique_channels,
                'unique_items': unique_items,
                'unique_months': unique_months,
                'analysis_period': f"{yyyymm_start[:4]}ë…„ {yyyymm_start[4:6]}ì›” ~ {yyyymm_end[:4]}ë…„ {yyyymm_end[4:6]}ì›”"
            },
            'channel_summary': channel_summary,
            'raw_data': {
                'sample_records': [
                    {
                        'PST_YYYYMM': r.get('PST_YYYYMM', ''),
                        'CHNL_NM': r.get('CHNL_NM', ''),
                        'CLASS3': r.get('CLASS3', ''),
                        'SALE_AMT': float(r.get('SALE_AMT', 0)),
                        'SALE_AMT_CHNL_TTL': float(r.get('SALE_AMT_CHNL_TTL', 0)),
                        'SALE_RATIO': float(r.get('SALE_RATIO', 0)),
                        'IN_YMM_RNK': int(r.get('IN_YMM_RNK', 0)),
                        'IN_CHNL_RNK': int(r.get('IN_CHNL_RNK', 0))
                    }
                    for r in records[:50]
                ],
                'total_records_count': len(records)
            },
            'trend_data': {
                'trend_months': sorted(list(set(r.get('PST_YYYYMM', '') for r in records))),
                'monthly_totals': monthly_totals_list,
                'monthly_details': [
                    {
                        'yyyymm': r.get('PST_YYYYMM', ''),
                        'chnl_nm': r.get('CHNL_NM', ''),
                        'class3': r.get('CLASS3', ''),
                        'sale_amt': round(float(r.get('SALE_AMT', 0)) / 1000000, 2),
                        'sale_ratio': float(r.get('SALE_RATIO', 0))
                    }
                    for r in records
                ]
            }
        }
        
        # íŒŒì¼ ì €ì¥ (4-1-1-2ë¡œ ì €ì¥)
        filename = f"4-1-1-2.{brd_cd}_ì±„ë„ë³„_ë§¤ì¶œ_ì¢…í•©ë¶„ì„(12ê°œì›”ì¶”ì´)"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥ (analysis_dataì˜ sectionsë¥¼ ì¡°í•©)
        markdown_content = f"# {analysis_data.get('title', 'ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

def analyze_ad_expense(yyyymm, brd_cd):
    """ê´‘ê³ ì„ ì „ë¹„ ì¶”ì´ ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ê´‘ê³ ì„ ì „ë¹„ ì¶”ì´ ë¶„ì„ ì‹œì‘: {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ({yyyymm})")
    print(f"{'='*60}")
    
    # DB ì—°ê²°
    engine = get_db_engine()
    
    try:
        # ì „ë…„ ë™ì›” ê³„ì‚°
        current_year = int(yyyymm[:4])
        current_month = int(yyyymm[4:6])
        previous_year = current_year - 1
        yyyymm_py = f"{previous_year:04d}{current_month:02d}"
        
        print(f"ë¶„ì„ ê¸°ê°„: {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›”")
        
        # 1. ë‹¹í•´/ì „ë…„ ì„¸ë¶€ ë‚´ì—­ ì¿¼ë¦¬ ì‹¤í–‰
        detail_sql = get_ad_expense_detail_query(yyyymm, yyyymm_py, brd_cd)
        detail_df = run_query(detail_sql, engine)
        detail_records = detail_df.to_dicts()
        
        if not detail_records:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # 2. ì „ì²´ í•©ê³„ ê³„ì‚°
        curr_total = sum(float(r.get('AD_TTL_AMT', 0)) for r in detail_records if r.get('PST_YYYYMM') == yyyymm)
        prev_total = sum(float(r.get('AD_TTL_AMT', 0)) for r in detail_records if r.get('PST_YYYYMM') == yyyymm_py)
        change_amount = curr_total - prev_total
        change_pct = (change_amount / prev_total * 100) if prev_total != 0 else 0
        
        print(f"ì „ë…„ í•©ê³„: {prev_total:,.0f}ì› ({prev_total/1000000:.2f}ë°±ë§Œì›)")
        print(f"ë‹¹í•´ í•©ê³„: {curr_total:,.0f}ì› ({curr_total/1000000:.2f}ë°±ë§Œì›)")
        print(f"ë³€í™”ì•¡: {change_amount:,.0f}ì› ({change_pct:.1f}%)")
        
        # 3. 12ê°œì›” ì¶”ì„¸ ë°ì´í„° (í˜„ì¬ ì›”ë¶€í„° 12ê°œì›” ì „ê¹Œì§€)
        trend_months = []
        for i in range(12):
            year = current_year
            month = current_month - i
            while month <= 0:
                month += 12
                year -= 1
            trend_months.append(f"{year:04d}{month:02d}")
        trend_months.reverse()
        
        trend_sql = get_ad_expense_trend_query(trend_months, brd_cd)
        trend_df = run_query(trend_sql, engine)
        trend_records = trend_df.to_dicts()
        
        # 4. ì›”ë³„ í•©ê³„ ê³„ì‚°
        monthly_totals = {}
        for record in trend_records:
            month = record.get('PST_YYYYMM', '')
            amount = float(record.get('TTL_USE_AMT', 0))
            if month not in monthly_totals:
                monthly_totals[month] = 0
            monthly_totals[month] += amount
        
        monthly_totals_list = [
            {'yyyymm': month, 'total_amount': round(amount / 1000000, 2)}
            for month, amount in sorted(monthly_totals.items())
        ]
        
        # 5. ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì •ë¦¬
        categories = []
        prev_year_dict = {}
        curr_year_dict = {}
        
        for record in detail_records:
            pst_yyyymm = record.get('PST_YYYYMM', '')
            ctgr2 = record.get('CTGR2', '')
            ctgr3 = record.get('CTGR3', '')
            gl_nm = record.get('GL_NM', '')
            amount = float(record.get('AD_TTL_AMT', 0))
            
            key = f"{ctgr2}|{ctgr3}|{gl_nm}"
            
            if pst_yyyymm == yyyymm_py:
                prev_year_dict[key] = {
                    'ctgr2': ctgr2,
                    'ctgr3': ctgr3,
                    'gl_nm': gl_nm,
                    'amount': amount
                }
            elif pst_yyyymm == yyyymm:
                curr_year_dict[key] = {
                    'ctgr2': ctgr2,
                    'ctgr3': ctgr3,
                    'gl_nm': gl_nm,
                    'amount': amount
                }
        
        # ëª¨ë“  í‚¤ í†µí•©
        all_keys = set(prev_year_dict.keys()) | set(curr_year_dict.keys())
        
        for key in all_keys:
            prev_data = prev_year_dict.get(key, {'amount': 0, 'ctgr2': '', 'ctgr3': '', 'gl_nm': ''})
            curr_data = curr_year_dict.get(key, {'amount': 0, 'ctgr2': '', 'ctgr3': '', 'gl_nm': ''})
            
            prev_amt = prev_data['amount'] / 1000000
            curr_amt = curr_data['amount'] / 1000000
            change_amt = curr_amt - prev_amt
            change_pct_val = (change_amt / prev_amt * 100) if prev_amt != 0 else 0
            
            categories.append({
                'ctgr2': curr_data.get('ctgr2') or prev_data.get('ctgr2', ''),
                'ctgr3': curr_data.get('ctgr3') or prev_data.get('ctgr3', ''),
                'gl_nm': curr_data.get('gl_nm') or prev_data.get('gl_nm', ''),
                'prev_year': round(prev_amt, 2),
                'curr_year': round(curr_amt, 2),
                'change': round(change_amt, 2),
                'change_pct': round(change_pct_val, 1),
                'is_new': prev_amt == 0 and curr_amt > 0,
                'is_discontinued': prev_amt > 0 and curr_amt == 0
            })
        
        # 6. ì¹´í…Œê³ ë¦¬ ìš”ì•½
        increased = [c for c in categories if c['change'] > 0]
        decreased = [c for c in categories if c['change'] < 0]
        new_investments = [c for c in categories if c['is_new']]
        discontinued = [c for c in categories if c['is_discontinued']]
        
        # 7. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (JSON í˜•ì‹ ì‘ë‹µ ìš”ì²­)
        total_records_json = json.dumps([
            {'PST_YYYYMM': yyyymm_py, 'TOTAL_AMT': prev_total},
            {'PST_YYYYMM': yyyymm, 'TOTAL_AMT': curr_total}
        ], ensure_ascii=False, indent=2)
        
        detail_records_json = json.dumps([
            {
                'PST_YYYYMM': r.get('PST_YYYYMM', ''),
                'BRD_CD': brd_cd,
                'BRD_NM': BRAND_CODE_MAP.get(brd_cd, brd_cd),
                'CTGR1': r.get('CTGR1', ''),
                'CTGR2': r.get('CTGR2', ''),
                'CTGR3': r.get('CTGR3', ''),
                'GL_NM': r.get('GL_NM', ''),
                'TTL_USE_AMT': float(r.get('AD_TTL_AMT', 0))
            }
            for r in detail_records
        ], ensure_ascii=False, indent=2)
        
        prompt = f"""
ë„ˆëŠ” F&F ê·¸ë£¹ì˜ {BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œ ë§ˆì¼€íŒ… ì „ëµ ì±…ì„ìì•¼. {previous_year}ë…„ {current_month}ì›”ê³¼ {current_year}ë…„ {current_month}ì›”ì˜ ê´‘ê³ ì„ ì „ë¹„ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… íˆ¬ì íš¨ìœ¨ì„±ê³¼ ìµœì í™” ë°©ì•ˆì„ ì œì‹œí•´ì•¼ í•´.

**ë¶„ì„ ê¸°ê°„**
- ë‹¹í•´: {current_year}ë…„ {current_month}ì›”
- ì „ë…„: {previous_year}ë…„ {current_month}ì›”

<ë¶„ì„ ëª©í‘œ>
{BRAND_CODE_MAP.get(brd_cd, brd_cd)} ë¸Œëœë“œì˜ {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›” ê´‘ê³ ì„ ì „ë¹„ íˆ¬ì ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì˜ íš¨ê³¼ì„±ê³¼ í–¥í›„ ì˜ˆì‚° ë°°ë¶„ ì „ëµì„ ê²½ì˜ê´€ë¦¬íŒ€ì—ê²Œ ìˆ˜ë¦½í•´ì¤˜.

<ì „ì²´ í•©ê³„ ë°ì´í„°>
{total_records_json}

<ì„¸ë¶€ ê³„ì •ë³„ ë°ì´í„°>
{detail_records_json}

<ìš”êµ¬ì‚¬í•­>
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•´ì¤˜.

{{
  "title": "ê´‘ê³ ë¹„ ë¶„ì„",
  "sections": [
    {{
      "sub_title": "íˆ¬ì ë°©í–¥ì„± ì¢…í•© í‰ê°€",
      "ai_text": "ì „ë…„ëŒ€ë¹„ {previous_year}ë…„ {current_month}ì›” vs {current_year}ë…„ {current_month}ì›” ê´‘ê³ ë¹„ ë³€í™”ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•œ ë‚´ìš© (ì˜ˆ: ì„ íƒì  ì¶•ì†Œ - íš¨ìœ¨ì„± ì¤‘ì‹¬ ì˜ˆì‚° ì¬ë°°ë¶„ ë“±)"
    }},
    {{
      "sub_title": "íš¨ìœ¨ì  íˆ¬ì ì˜ì—­",
      "ai_text": "íš¨ê³¼ì ì¸ íˆ¬ì ì˜ì—­ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë‚˜ì—´ (ì˜ˆ: â€¢ ëª¨ë¸ë£Œ ì‹ ê·œ íˆ¬ì…: 122.9ë°±ë§Œì›ìœ¼ë¡œ ë¸Œëœë“œ ì´ë¯¸ì§€ ì œê³  ë° ì†Œë¹„ì ì–´í•„ ê°•í™” ë“±)"
    }},
    {{
      "sub_title": "ì£¼ì˜ í•„ìš” ì˜ì—­",
      "ai_text": "ì£¼ì˜ê°€ í•„ìš”í•œ ì˜ì—­ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë‚˜ì—´ (ì˜ˆ: â€¢ E-BIZ ë§¤ì²´ê´‘ê³  ì¦ê°€: 9.2â†’14.0ë°±ë§Œì›(+51.8%)ë¡œ ê¸‰ê²©í•œ ì¦ê°€ ì›ì¸ ë“±)"
    }},
    {{
      "sub_title": "ì´ìƒì§•í›„ ë° ë¦¬ìŠ¤í¬ ê°ì§€",
      "ai_text": "ì´ìƒì§•í›„ì™€ ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª… (ì˜ˆ: â€¢ ì˜ˆì‚° ë°°ë¶„ì˜ ê·¹ë‹¨ì  ë³€í™”: ì¼ë¶€ ê³„ì •ì˜ ì „ì•¡ ì‚­ê°(ê¸°íƒ€ ê´‘ê³ ë¹„)ê³¼ ì‹ ê·œ ëŒ€ê·œëª¨ íˆ¬ì…(ëª¨ë¸ë£Œ)ì´ ë™ì‹œ ë°œìƒí•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì˜ ê¸‰ê²©í•œ ë°©í–¥ ì „í™˜ì„ ì‹œì‚¬í•©ë‹ˆë‹¤ ë“±)"
    }},
    {{
      "sub_title": "ë§ˆì¼€íŒ… ì „ëµ ìµœì í™” ë°©ì•ˆ",
      "ai_text": "ë‹¨ê¸° ì „ëµ ë°©í–¥ê³¼ ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ (ì˜ˆ: ### ì¦‰ì‹œ ì‹¤í–‰ ë°©ì•ˆ\\n1. ëª¨ë¸ ë§ˆì¼€íŒ… íš¨ê³¼ ì¸¡ì •: ... ë“±)"
    }}
  ]
}}

<ì‘ì„± ê°€ì´ë“œë¼ì¸>
- ê° ì„¹ì…˜ì˜ ai_textëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
- ìˆ«ìëŠ” ë°±ë§Œì› ë‹¨ìœ„ë¡œ í‘œì‹œí•˜ê³  ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ ê²ƒ
- ëª¨ë“  ê´‘ê³ ì„ ì „ë¹„ ê³„ì • (CTGR3) ëˆ„ë½ ì—†ì´ ë¶„ì„
- ì „ë…„ëŒ€ë¹„ ë³€í™”ì— ëŒ€í•œ êµ¬ì²´ì  ì›ì¸ê³¼ íš¨ê³¼ ë¶„ì„
- ë‹¨ê¸° ì „ëµ ë°©í–¥ì„± ì œì‹œì™€ ì¤‘ì¥ê¸° ì „ëµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ë¶ˆë¦¿ í¬ì¸íŠ¸ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹(-, â€¢) ì‚¬ìš© ê°€ëŠ¥
- ì¤„ë°”ê¿ˆì€ ë°˜ë“œì‹œ \\nì„ ì‚¬ìš©í•˜ì—¬ í‘œì‹œ (ì˜ˆ: "ì²« ë²ˆì§¸ ì¤„\\në‘ ë²ˆì§¸ ì¤„")
- ai_text ë‚´ì—ì„œ ì—¬ëŸ¬ ë¬¸ë‹¨ì´ë‚˜ í•­ëª©ì„ ë‚˜ëˆŒ ë•ŒëŠ” \\n\\nì„ ì‚¬ìš©
- ë¶ˆë¦¿ í¬ì¸íŠ¸ë‚˜ ë¦¬ìŠ¤íŠ¸ í•­ëª© ì‚¬ì´ì—ëŠ” \\nì„ ì‚¬ìš©
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´)

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì¤˜:
"""
        
        # 8. LLM í˜¸ì¶œ (JSON ì‘ë‹µ)
        analysis_response = call_llm(prompt, max_tokens=4000)
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        analysis_response = analysis_response.strip()
        if analysis_response.startswith('```json'):
            analysis_response = analysis_response[7:]
        if analysis_response.startswith('```'):
            analysis_response = analysis_response[3:]
        if analysis_response.endswith('```'):
            analysis_response = analysis_response[:-3]
        analysis_response = analysis_response.strip()
        
        try:
            analysis_data = json.loads(analysis_response)
        except json.JSONDecodeError as e:
            print(f"[WARNING] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"[WARNING] ì‘ë‹µ ë‚´ìš©: {analysis_response[:500]}")
            # ê¸°ë³¸ êµ¬ì¡°ë¡œ ëŒ€ì²´
            analysis_data = {
                "title": "ê´‘ê³ ë¹„ ë¶„ì„",
                "sections": [
                    {"sub_title": "ë¶„ì„ ê²°ê³¼", "ai_text": analysis_response}
                ]
            }
        
        # 9. JSON ë°ì´í„° ìƒì„±
        json_data = {
            'brand_cd': brd_cd,
            'yyyymm': yyyymm,
            'analysis_data': analysis_data,
            'summary': {
                'prev_year_total': round(prev_total / 1000000, 2),
                'curr_year_total': round(curr_total / 1000000, 2),
                'change_amount': round(change_amount / 1000000, 2),
                'change_pct': round(change_pct, 1),
                'investment_direction': 'ì¦ê°€' if change_amount > 0 else 'ì¶•ì†Œ' if change_amount < 0 else 'ìœ ì§€'
            },
            'categories': categories,
            'category_summary': {
                'increased': increased,
                'decreased': decreased,
                'new_investments': new_investments,
                'discontinued': discontinued
            },
            'raw_data': {
                'total_records': [
                    {'PST_YYYYMM': yyyymm_py, 'TOTAL_AMT': prev_total},
                    {'PST_YYYYMM': yyyymm, 'TOTAL_AMT': curr_total}
                ],
                'detail_records': [
                    {
                        'PST_YYYYMM': r.get('PST_YYYYMM', ''),
                        'BRD_CD': brd_cd,
                        'BRD_NM': BRAND_CODE_MAP.get(brd_cd, brd_cd),
                        'CTGR1': r.get('CTGR1', ''),
                        'CTGR2': r.get('CTGR2', ''),
                        'CTGR3': r.get('CTGR3', ''),
                        'GL_NM': r.get('GL_NM', ''),
                        'TTL_USE_AMT': float(r.get('AD_TTL_AMT', 0))
                    }
                    for r in detail_records
                ]
            },
            'trend_data': {
                'trend_months': trend_months,
                'monthly_totals': monthly_totals_list,
                'monthly_details': [
                    {
                        'yyyymm': r.get('PST_YYYYMM', ''),
                        'ctgr2': r.get('CTGR2', ''),
                        'ctgr3': r.get('CTGR3', ''),
                        'gl_nm': r.get('GL_NM', ''),
                        'amount': round(float(r.get('TTL_USE_AMT', 0)) / 1000000, 2)
                    }
                    for r in trend_records
                ]
            }
        }
        
        # 10. íŒŒì¼ ì €ì¥
        filename = f"6-1-1-1.{brd_cd}_ê´‘ê³ ì„ ì „ë¹„_ì¶”ì´ë¶„ì„"
        save_json(json_data, filename)
        
        # Markdownë„ ì €ì¥ (analysis_dataì˜ sectionsë¥¼ ì¡°í•©)
        markdown_content = f"# {analysis_data.get('title', 'ê´‘ê³ ë¹„ ë¶„ì„')}\n\n"
        for section in analysis_data.get('sections', []):
            markdown_content += f"## {section.get('sub_title', '')}\n\n"
            markdown_content += f"{section.get('ai_text', '')}\n\n"
        save_markdown(markdown_content, filename)
        
        print(f"[OK] ë¶„ì„ ì™„ë£Œ!\n")
        return json_data
        
    finally:
        engine.dispose()

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================
if __name__ == '__main__':
    # ë¶„ì„ ì„¤ì •
    yyyymm = '202509'  # ë¶„ì„í•  ë…„ì›”
    brd_cd = 'M'       # ë¸Œëœë“œ ì½”ë“œ
    
    # ë¶„ì„ ì‹¤í–‰ (ì›í•˜ëŠ” ë¶„ì„ë§Œ ì£¼ì„ í•´ì œ)
    analyze_channel_sales(yyyymm, brd_cd)  # ì±„ë„ë³„ ë§¤ì¶œ ë¶„ì„ (4-1-1-1)
    analyze_channel_sales_overall(yyyymm, brd_cd)  # ì±„ë„ë³„ ë§¤ì¶œ ì¢…í•©ë¶„ì„ (4-1-1-2)
    analyze_ad_expense(yyyymm, brd_cd)  # ê´‘ê³ ì„ ì „ë¹„ ì¶”ì´ ë¶„ì„(6-1-1-1)
